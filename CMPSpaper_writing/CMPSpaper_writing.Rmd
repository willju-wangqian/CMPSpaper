---
title: An Open-Source Implementation of the CMPS Algorithm for Assessing  Similarity of Bullet Signatures
header-includes:
  - \usepackage{xcolor}
  - \usepackage{longtable}
  - \usepackage{adjustbox}            
  - \usepackage[font=small,skip=5pt]{caption}
  - \usepackage{subcaption}
  - \usepackage{afterpage}
author:
  # see ?rjournal_article for more information
  - name: Will W. Ju
    affiliation: Department of Statistics
    address:
    - Center for Statistics and Applications in Forensic Evidence
    - Iowa State University
    - 2438 Osborn Dr
    - Ames, IA 50011
    url: https://github.com/willju-wangqian
    email:  wju@iastate.edu
    orcid: 0000-0002-9977-377X
  - name: Heike Hofmann
    url: https://github.com/heike
    email: hofmann@iastate.edu
    orcid: 0000-0002-9079-593X
    affiliation: Department of Statistics
    address:
    - Center for Statistics and Applications in Forensic Evidence
    - Iowa State University
    - 2438 Osborn Dr
    - Ames, IA 50011
abstract: >
  An abstract of less than 150 words.
preamble: |
  % Any extra LaTeX you need in the preamble
  
# per R journal requirement, the bib filename should be the same as the output 
# tex file. Don't forget to rename the bib file and change this example value.
bibliography: CMPSpaper-writing.bib

output: rticles::rjournal_article
---


```{=tex}
\newcommand{\hh}[1]{{\textcolor{orange}{#1}}}
\newcommand{\wj}[1]{{\textcolor{blue}{#1}}}
\setlength{\parindent}{0pt}
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(tidyverse)
library(bulletxtrctr)
library(knitr)
library(kableExtra)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  out.width = "\\textwidth",
  fig.align = "center",
#  cache=TRUE,
  dpi = 100
)
```


```{r setup_knitr, echo=FALSE}
## From Josh O'Brien's stackoverflow answer:
## http://stackoverflow.com/questions/11030898/knitr-how-to-align-code-and-plot-side-by-side
## These two settings control text width in codefig vs. usual code blocks
partWidth <- 35
fullWidth <- 60
options(width = fullWidth)

##  (1) CHUNK HOOK FUNCTION
##   First, to set R's textual output width on a per-chunk basis, we
## need to define a hook function which temporarily resets global R's
## option() settings, just for the current chunk
knit_hooks$set(r.opts = local({
    ropts <- NA
    function(before, options, envir) {
        if (before) {
            ropts <<- options(options$r.opts)
        } else {
            options(ropts)
        }
    }
}))

## (2) OUTPUT HOOK FUNCTION

##   Define a custom output hook function. This function processes _all_
## evaluated chunks, but will return the same output as the usual one,
## UNLESS a 'codefig' argument appeared in the chunk's header.  In that
## case, wrap the usual textual output in LaTeX code placing it in a
## narrower adjustbox environment and setting the graphics that it
## produced in another box beside it.

defaultChunkHook <- environment(knit_hooks[["get"]])$defaults$chunk

codefigChunkHook <- function(x, options) {
  main <-  defaultChunkHook(x, options)
  before <-
    "\\vspace{1em}
\\begin{adjustbox}{valign=t}
\\begin{minipage}{.39\\textwidth}\n"
  after <-
    paste("\\vspace{1em}
\\end{minipage}
\\begin{minipage}{.59\\textwidth}",
    paste0("\\includegraphics[width=\\textwidth]{CMPSpaper_writing_files/figure-latex/",
                 options[["label"]], "-1.pdf}
\\end{minipage}
\\end{adjustbox}"),
          sep = "\n")
  ## Was a codefig option supplied in chunk header?
  ## If so, wrap code block and graphical output with needed LaTeX code.
  if (!is.null(options$codefig)) {
    main <- gsub("```","", main)
    main <- gsub("=latex","", main)
    main <- paste0("{\\small ", main, "}")
    return(sprintf("%s\n%s\n%s", before, main, after))
  } else {
    return(main)
  }
}

knit_hooks[["set"]](chunk = codefigChunkHook)


## (3) TEMPLATE
##   codefig=TRUE is just one of several options needed for the
## side-by-side code block and a figure to come out right. Rather
## than typing out each of them in every single chunk header, we
## define a _template_ which bundles them all together. Then we can
## set all of those options simply by typing opts.label="codefig".

opts_template[["set"]](
codefig = list(codefig = TRUE, fig.show = "hide",
               r.opts = list(width = partWidth),
               tidy.opts = list(width.cutoff = partWidth)))
```




## Introduction


In this paper we present an open-source implementation of the algorithm of the Congruent Matching Profile Segments (CMPS) method. @cmps developed the CMPS method for "objective comparison of striated tool marks" and demonstrated its use in some examples of comparing bullet signature correlations. Although @cmps conceptually described the CMPS algorithm  in their paper, the authors did not release an implementation of their method. Thus, our effort here is to introduce the CMPS method to the `R` [@R] community and provide an open-source, publicly available implementation of the algorithm  to use, review, and  improve. Our implementation is made available as part of the  `R` package  `CMPS` on GitHub at \url{https://github.com/willju-wangqian/CMPS}. 

 Firearm examination has  played an important role in  convictions in the United States criminal justice system. \hh{Do we have a number or a percentage of cases where firearm examination has played a role? or maybe gun violence? XXX}
 
An important task of firearm examination is to answer the question of whether two pieces of evidence come from the same source or whether a piece of evidence matches a sample obtained from a specific firearm. Here, in particular, we are interested to determine whether two bullets were fired from the same gun barrel. 
Assessing the similarity between two bullets is based on a comparison of  striation marks acquired during the firing process as bullets are propelled through the barrel. Current state of art sees firearms examiners make an assessment of similarity based on a visual comparison, generally, using a comparison microscope. This practice has been criticized for its lack of objectivity and the associated problem in calculating an error rate [@pcast].

A report published by @nrc states that "[m]uch forensic evidence-including, for example, bite marks and firearm and toolmark identificationâ€”is introduced in criminal trials without any meaningful scientific validation, determination of error rates, or reliability testing to explain the limits of the discipline." To overcome those criticisms and concerns, researchers have been making an effort to build databases and develop frameworks and algorithms that bring an objective and quantitative assessment into the field [@nistdb, @brundage, @hamby, @Hamby:2019, @song2005, @ChumbleyL_Scott2010VoTM, @aoas, @pmid30444940;@cmps]. \wj{Note that this is not an exhaustive list of these efforts.} The notion of bullet signatures is one of the results of these efforts. Bullet signatures can be extracted from bullet land engraved areas (LEAs), typically one for each land engraved area, and how those bullet signatures are extracted from scans will be discussed in the Background section. Since bullet signatures can numerically describe the striation marks on the bullet and can be understood by algorithms, they played an important role in bringing objectivity into the field. 
In the following sections we will: review the background of bullet signature comparisons, discuss how we followed the idea described by @cmps for the implementation of the CMPS algorithm, and present results of applying our implementation to real data. 

## Background 


### Hamby Data Set

The datasets we worked with come from the James Hamby Consecutively Rifled Ruger Barrel Study [@brundage; @hamby; @Hamby:2019],  in particular, Hamby set 252 and Hamby set 44. 
For each Hamby set, a total of 35 bullets is fired from ten consecutively manufactured Ruger P-85 pistol barrels. Two bullets are fired from each barrel, making up a set of 20 reference bullets. An additional 15 bullets are fired from these ten barrels in a fashion unknown to the study participant. The aim of the Hamby Study was to have firearms examiners identify which barrel each of the 15 questioned bullets was fired from. The Ruger P-85 barrels are traditionally rifled barrels with six grooves and lands as shown in \autoref{fig:bullet}. During the firing process, grooves and lands are engraved on a bullet. Firearms examiners use striation marks on land engraved areas (LEAs) for their visual comparison. For algorithmic purposes, 
3D topographical images land engraved areas were obtained and stored in  x3p format (XML 3-D Surface Profile). The x3p format provides a standard way of exchanging 2D and 3D profile data. It conforms to the ISO5436-2 standard [http://sourceforge.net/p/open-gps/mwiki/X3p/]  adopted by the OpenFMC (Open Forensic Metrology Consortium), a group of firearm forensics researchers who contributes to the establishment of best practices of using metrology in forensic science. Hamby set 252 were scanned using a NanoFocus lens at 20x magnification with the scan resolution being 1.5625 \textmu m $\times$ 1.5625 \textmu m per pixel. Hamby set 44 was scanned at the Roy J Carver High-Resolution microscopy lab at Iowa State. These scans were acquired with a Sensofar Confocal Light Microscope at 20x magnification for a nominal resolution of 0.645 \textmu m $\times$ 0.645 \textmu per pixel.  Both Hamby set 252 and Hamby set 44 are publicly available on the NIST Ballistics Database Project [@nistdb].


### Extracting signatures from LEA scans

The automated framework  used in this paper was proposed by @aoas. In order to obtain bullet signatures from the x3p files of bullet land engravings, we use the `R` packages `x3ptools` [@x3ptools] and `bulletxtrctr` [@bulletxtrctr]. `x3ptools` is a package to read, write, and generally, process x3p files. The `bulletxtrctr` package implements a pipeline for extracting and comparing signatures from scans of land-engraved areas.

\autoref{fig:process} gives an overview of all of the steps in the process from scan to signatures.
\autoref{fig:process}(a) shows a rendering of a 3d scan of a bullet land  engraved area. The raised portion of the surface on the left and right of the scan are parts of the adjacent groove engraved areas (GEAs), the middle area shows a land-engraved area (LEA) with well expressed striation marks. The first step of obtaining the bullet signature is to extract a cross-section at a fixed height along the land engraving.

The white horizontal line in \autoref{fig:process}(a) indicates which cross-section was identified by the algorithm to represent the LEA; \autoref{fig:process}(b) shows the corresponding cross-sectional view. 
Groove engraved areas are removed from the analysis as indicated by the vertical blue lines in \autoref{fig:process}(c) and \autoref{fig:process}(d)). A non-parametric LOESS smooth  [@loess] is fitted to capture the bullet curvature (\autoref{fig:process}(e)) and, finally, the **bullet signature** (\autoref{fig:process}(f)) is obtained as residuals of the cross-section and the fitted smooth. 
Note, that in @cmps bullet signatures are  referred to as bullet profiles. However, to avoid confusion, we distinguish the notion of bullet signatures from bullet profiles. Bullet profiles are shown in panels (b), (c), and (d) of \autoref{fig:process}, while \autoref{fig:process}(f) shows the corresponding bullet signature.
Identifiying the groove engraved areas correctly is fundamental for a correct down-stream analysis of the signatures. To allow for a human-in-the middle inspection and intervention we have provided an interactive web-application, implemented as `R` Shiny App [@shiny],  `bulletinspectR` to identify and correct those errors. 
\hh{An example of the extraction process with corresponding code and parameter settings can be found at XXX.}
Note that the process of extracting signatures might be different from the one used in @cmps because no code or parameter settings are made available publicly.


```{r bullet, echo=FALSE, out.width=".8\\textwidth", fig.cap="Photo of a traditionally rifled gun barrel (left) and a fired bullet (right)."}
knitr::include_graphics("img/barrel_bullet_ps.png", dpi = 100)
```


```{r process, echo=FALSE, out.width=".9\\textwidth", fig.cap="A framework of obtaining a bullet signature. (a) front view of a scanned land engraved area (LEA). The selected crosscut location is indicated by the white line. (b) view of the cross-section of the land engraved area at the white line in (a). (c) the crosscut data plotted in 2D; blue vertical lines indicate the position of left and right grooves. (d) the crosscut data after chopping the left and right grooves. (e) the fitted curvature using LOESS. (f) after removing the curvature from the crosscut data, the bullet signature is obtained"}
knitr::include_graphics("img/figure1_v2.PNG", dpi = 100)
```




### Conceptual idea of CMPS
\hh{Most algorithms for comparing striation marks are based on the digitized signatures XXX} and produce a similarity score [@song2005, @ChumbleyL_Scott2010VoTM, @aoas, @pmid30444940 ].
 The congruent matching profile segments (CMPS) algorithm, developed by @cmps for "objective comparison of striated tool marks", is one such algorithm. The algorithm's main idea  is to take a set of consecutive and non-overlapping basis segments from  the reference   and  for each segment find the "best" registration position on the comparison  (the other bullet signature) with respect to their cross-correlation values. From a comparison of these registration positions, a **congruent registration position** is identified, and the number of basis segments taking the congruent registration position is the CMPS score. 
  High CMPS scores are achieved between more similar signatures and are therefore indicative of a same-source pair. Low scores between pairs of signatures are attributed to different source pairs.
  \hh{XXX What threshold did @cmps identify as the boundary between different source and same source? And what was the error rate in their example?}
  \wj{they didn't talk about a specific threshold or error rates} \hh{XXX Is there a way to infer the error based on the example? ... 'while the authors did not mention a specific threshold of the CMPS to distinguish between same-source and different-source comparison, a CMPS value of Y results in an error rate of Z in the example.'}
 The CMPS algorithm can assist firearm examiners with drawing a conclusion about the source of a comparison pair. Unfortunately, @cmps did not release any code or specific parameter settings for their implementation of the CMPS algorithm. 
Thus, in this paper we present an open-source implementation of the CMPS algorithm \hh{in the R package CMPS available from XXX github / CRAN}. 
With our implementation, one can compute the CMPS score of a comparison using the following code:

```{r, eval=FALSE}
# install.packages("devtools") 
# devtools::install_github("willju-wangqian/CMPS")

library(CMPS)
data(bullets)

sig1 <- bullets$sigs[[2]]$sig
sig2 <- bullets$sigs[[9]]$sig
sig3 <- bullets$sigs[[10]]$sig

cmps.result.KM <- extract_feature_cmps(sig1, sig2)
cmps.result.KNM <- extract_feature_cmps(sig1, sig3)
```

In this example, the comparison between `sig1` and `sig2`, two signatures coming from the same source (a known-match comparison), gets a CMPS score of 17; the comparison between `sig1` and `sig3`, two signatures coming from different sources (a known non-match comparison), gets a CMPS score of 1.


We also implemented graphing tools for users to better understand these results as well as the algorithm itself.

The section "Implementation" will go through the algorithm and show how to use the "CMPS" package. An further example that illustrates the main points are also included. The section "Results" presents the results of evaluating the CMPS package using Hamby set 252 and Hamby set 44. And the last section covers some final discussion and conclusions.


## Implementation

**Algorithm.** 

Conceptually, the CMPS algorithm consists of three main steps:

1. **cut the reference signature into consecutive, non-overlapping and equal-length basis segments:**
The command `get_segs(x, len=50)` implements this step:  it takes  bullet signature `x` in the format of a numeric vector and cuts it into consecutive, non-overlapping and equal-length segments of length `len`, which are referred to as "basis segments".

\wj{the followings are revised}

2. **identify candidate positions:** For each basis segment a set of candidate registration  positions on the comparison signature is identified based on the segment's similarity to the comparison. In a first step, the cross-correlation function of the segment to the comparison is calculated, then a number of positions with high correlation values are identified as candidate positions. In case multiple segment lengths are considered, the length of each basis segment is doubled and these two steps are repeated. Only when candidate positions coincide (or are similar enough), they are considered further. \autoref{fig:segplots} and \autoref{fig:seg_all} illustrate these ideas.

    + **Calculate the cross-correlation curve:**  Calculate the cross-correlation curve between a basis segment `x` and the comparison signature `y` using the function `get_ccf4(x, y, ...)` as shown in \autoref{fig:segplot2}. The position indicates the lag by which a basis segment is moved with respect to its original placement. A position is considered "good" if it results in a peak in the cross-correlation between the basis segment and the comparison.

 
    + **Correlation peaks:** The parameter `npeaks.set` in `extract_feature_cmps(...)` determines the number of candidate positions and which strategy to  use to combine candidates: If `npeaks.set` is an integer vector of length 1, for example `npeaks.set = 5`, the positions of the top five peaks in the cross-correlation curve are identified as candidates for registration. This strategy is referred as "multi-peak inspection" in @cmps.

    +  **Multiple-length segments:** If `npeaks.set` is an integer vector of length more than 1, for example `npeaks.set = c(5, 3, 1)`, a multi segment lengths strategy will be used: finding top five peaks in the original scale, double the segment length and recalculate the cross-correlation function, then identify 3 peaks in the second scale and repeat the process for a basis segment that is doubled again to identify 1 peak in the third scale. \autoref{fig:seg_all} shows an example of 3 scales of basis segment 6 and their corresponding cross-correlation curves and identified peaks. If a single position (with a tolerance zone determined by `Tx`) results in a top peak in the cross-correlation curve in all three scales, it is called a consistent correlation peak and identified as a candidate position for registration. Note that in @cmps the last element of `npeaks.set` in the multi segment lengths strategy is always set to be 1. Additionally, this strategy is also referred as "multi-peak inspection at different segment lengths" in @cmps.



3. **determine the congruent registration position:** \wj{A candidate position "receives" `votes` from basis segments that identify it or a close position within a tolerance zone of `Tx` as a candidate position in step 2. Votes for all candidate positions} are tallied and the position with the highest number of votes gets chosen as the *congruent registration position*. Basis segments with a congruent registration position are called "congruent matching profile segments" (CMPS). The total number of CMPS is the CMPS score of the comparison. \hh{XXX what happens when there are ties after the vote?}

In the CMPS package, these three steps are implemented using a set of key functions:


* `get_seg_scale(segments, nseg, scale = 2)` takes a basis segment and increases its segment length. `segments` is a list containing all basis segments, generated by the function `get_segs(...)`; `nseg` is an integer indicating which basis segment the function should work with. `scale=1` gives the original length of the basis segment. Increasing `scale` by 1 will double the segment length. 

* `get_ccr_peaks(comp, segments, seg_scale, nseg = 1, npeaks = 5)` computes the cross-correlation curve between a basis or scaled segment and the comparison signature and finds peaks in the cross-correlation curve. The number of peaks detected is equal to `npeaks`, which is an integer. `segments`, `seg_scale`, and `nseg` determines the segment in the cross-correlation computation, and `comp` gives the comparison signature. If the multi segment lengths strategy is used, then `get_ccr_peaks(...)` is called in a `lapply()` for each scale of the basis segment. The resulting list is called `ccr.list`.

* `get_ccp(ccr.list, Tx = 25)` tries to identify the "consistent correlation peak" (defined in algorithm step 2) under the framework of multi segment lengths strategy. `ccr.list` is described in the previous bullet point, and `Tx` determines the size of a tolerance zone used in identifying the consistent correlation peak. \hh{XXX what happens when there is no consistent correlation peak?} `get_ccp(...)` returns `NULL` if there is no consistent correlation peak.


* `get_CMPS(input.ccp, Tx = 25)` \hh{XXX how is `get\_CMPS` different from the extract function?} tallies votes from all basis segments and determines the congruent registration position. A position "receives" a vote from a basis segment if this basis segment identifies this position or a closed-enough position (within a tolerance zone defined by `Tx`) as a candidate registration position in algorithm step 2. The goal is to find a shift in registration position that is agreed by the most number of basis segments, so the position receiving the most number of votes is the congruent registration position. In case of ties the middle position is taken as the congruent registration position. Basis segments with the congruent registration position identified are called "congruent matching profile segments" (CMPS). The total number of CMPS is the CMPS score.


Note that there are \hh{several} parameters in the CMPS algorithm \hh{that are left to} the users \hh{to decide}, such as the length of basis segments `seg_length` in step 1, the number of peaks `npeaks.set` identified on each scale level in step 2, and the length of the tolerance zone `Tx` in both step 2 and 3. 
In our implementation of the CMPS algorithm we used the parameters given in the original CMPS paper [@cmps] as the default values for these parameters. \hh{XXX However, the authors state that no cross-validation has been done - there might be also issues with respect to resolution of the scans. Further research is needed, until then users are advised to think of default values as starting values and consider alternatives}
<!--Additionally, as shown in @cmps, using multi segment lengths strategy reduces the number of "false positive" peaks in the cross-correlation curves, thus providing a more conservative way of identifying candidate positions.-->
The main function that combines all steps in the CMPS algorithm described above is called `extract_feature_cmps(...)`. Default values and some explanations of its parameters are as following:

```{r, eval=FALSE}
extract_feature_cmps(
  x,
  y,
  seg_length = 50,
  Tx = 25,
  npeaks.set = c(5, 3, 1),
  include = NULL
)
```


\wj{the followings are revised} \hh{XXX this section feels a bit repetitive}

* `x` and `y` are the two bullet signatures. Usually we take `x` as the reference signature (that will be divided into basis segments) and `y` as the comparison signature;
* `seg_length` specifies the length of basis segments [(in mm?)] mentioned in algorithm step 1; 
* `Tx` determines the size of the tolerance zone mentioned in both step 2 and 3;
* `npeaks.set` is a (vector of) integer value(s). This parameter determines which strategy to use to generate candidate positions and the number of peaks to be identified;
* `include` determines the output of the function. Besides the `CMPS.score`, many details of the comparison might be used to understand how the `CMPS.score` is computed. By default, `include = NULL` and the function output will only contain the `CMPS.score`; `include` can also be (an abbreviation of) one of or a vector of the following strings: `"nseg", "congruent.pos", "congruent.seg.idx", "segments", "parameters"`, and `"full_result"`. if `"full_result"` (or its abbreviation) is specified, the ouput will include everything listed below.
  - `nseg`: the number of basis segments we get from the reference signature; this is also the highest possible CMPS score of the comparison;
  - `congruent.pos`: the congruent registration position;
  - `congruent.seg.idx`: the indices of all congruent matching profile segments;
  - `ccp.list`: a list showing identified candidate positions of all basis segments; 
  - `pos.df`: a data frame containing all candidate positions and the number of votes they received;
  - `segments`: a list containing all basis segments;
  - `parameters`: a list containing all input arguments of `extract_feature_cmps`;
  
For more details, please check the documentation of `extract_feature_cmps` or use `?extract_feature_cmps`.

\wj{revised end}

<!-- [examples https://journal.r-project.org/archive/2019/RJ-2019-044/RJ-2019-044.pdf] -->
<!-- [https://journal.r-project.org/archive/2019/RJ-2019-002/RJ-2019-002.pdf] -->


\hh{XXX you need a bit of an overview here on the structure of what is coming next: in the remainder of the paper we showcase the use of the CMPS functionality on some examples ...}

**Installation**

The CMPS package is (not) publicly available from CRAN, and can be installed by 

```{r, eval=FALSE}
install.packages("CMPS")
```

The development version is available from Github can be installed by using 

```{r, eval=FALSE}
# install.packages("remotes") 
remotes::install_github("willju-wangqian/CMPS")
```



**An Example**

The `CMPS` package contains a simple example to illustrate the basic usage of the package. The data in this example are twelve bullet signatures obtained from two bullets in Hamby set 252 [@hamby].  The procedure for generating signatures from high-resolution 3D topographic scans of bullet lands used here follows the methodology described in @aoas (as discussed above). 
The two bullets under consideration here are known to have been fired from the same gun barrel, so for the 36 land-by-land comparisons, 6 comparison are from same-source pairs (known matches) while 30 are from different-source pairs (known non-matches). To access the example data, we use

```{r, eval=TRUE}
library(CMPS)
data(bullets)
```

`bullets$sigs` is a list of 12 numeric vectors corresponding to 12 bullet signatures. `bullets$source` contains the URLs to the corresponding x3p file containing the topographic scan  from the NIST Ballistics Toolmark Research Database [@nistdb]. 

\hh{XXX include some signatures here.}

```{r echo=FALSE, fig.cap="Signatures of all lands of bullet 1 in the top row, and of bullet 2 in the bottom row. Signatures in the second row are ordered to be in phase with the signatures above, i.e. ..."}
signatures <- bullets %>% unnest(sigs)
signatures <- signatures %>% mutate(
  bulletland = factor(bulletland, levels=c(paste(rep(c(1,2), each=6), c(1:6,2:6,1), sep="-")))
)
signatures %>% ggplot(aes(x = x/1000, y = sig)) + geom_line() + facet_wrap(~bulletland, ncol=6) +
  theme_bw() +
  xlab("Length in mm") +
  ylab("Relative height in micron")
```

The signatures of Land 4 of Bullet 1 and Land 5 of Bullet 2 are stored in objects `sigs2` and `sigs1`, respectively. This comparison is one of a pair of signatures that are known to be a match -- a KM (known match) comparison. We compute the CMPS score using two versions of the CMPS algorithm:




```{r, eval=TRUE}
sigs1 <- bullets$sigs[bullets$bulletland == "2-5"][[1]]
sigs2 <- bullets$sigs[bullets$bulletland == "1-4"][[1]]

# compute cmps

# algorithm with multi-peak insepction at three different segment scales
cmps_with_multi_scale <- 
  extract_feature_cmps(sigs1$sig, sigs2$sig, 
                       npeaks.set = c(5,3,1), include = "full_result")

# algorithm with multi-peak inspection at the basis scale only
cmps_without_multi_scale <- 
  extract_feature_cmps(sigs1$sig, sigs2$sig, 
                       npeaks.set = 5, include = "full_result")
```

\hh{How about you go into a description of the results from the function `extract\_feature\_cmps`?}

\wj{revised the following}
Since `npeaks.set = c(5,3,1)`, `cmps_with_multi_scale` uses the multi segment lengths strategy. On the other hand, `cmps_without_multi_scale` doesn't use the multi segment lengths strategy, and each basis segment finds 5 candidate positions due to `npeaks.set = 5`. Since `include = "full_result"` the outputs of `extract_feature_cmps(...)` contain everything listed in the previous section. Moreover, as mentioned before, multi segment lengths strategy provides a more conservative ways of finding candidate positions, so the `CMPS.score` of `cmps_with_multi_scale` is 9, while that of `cmps_without_multi_scale` is 12.
\wj{revised end}

```{r alternative, echo = FALSE}
lands <- unique(bullets$bulletland)

comparisons <- data.frame(expand.grid(land1 = lands[1:6], land2 = lands[7:12]), 
                          stringsAsFactors = FALSE)

comparisons <- comparisons %>% 
  left_join(bullets %>% select(bulletland, sig1=sigs),
            by = c("land1" = "bulletland")) %>%
  left_join(bullets %>% select(bulletland, sig2=sigs),
            by = c("land2" = "bulletland"))

comparisons <- comparisons %>% mutate(
  cmps = purrr::map2(sig1, sig2, .f = function(x, y) {
    extract_feature_cmps(x$sig, y$sig, include = "full")
    })
)

comparisons <- comparisons %>% 
  mutate(
    cmps_score = sapply(comparisons$cmps, function(x) x$CMPS.score),
    cmps_nseg = sapply(comparisons$cmps, function(x) x$nseg)
  )

comparisons <- comparisons %>%
  mutate(
    bulletA = gsub("(\\d)-\\d", "\\1", land1),
    landA = gsub("\\d-(\\d)", "\\1", land1),
    bulletB = gsub("(\\d)-\\d", "\\1", land2),
    landB = gsub("\\d-(\\d)", "\\1", land2)
  )

dframe <- comparisons %>% select(-sig1, -sig2)

dframe$samesource <- with(dframe, bullet_to_land_predict(land1=landA, land2=landB, cmps_score, difference=1))
```

**Visualize and Understand CMPS results**

We also implemented graphing tools for visualizing results of the CMPS algorithm. The goal is to provide users with tools to inspect each of the basis segments and to help them have a better understanding of how the algorithm works. \autoref{fig:sigplots} shows the plots generated by the first graphing function, `cmps_signature_plot()`, and continues with the example above. `cmps_signature_plot()` takes the output of `extract_feature_cmps(..., include = "full_result")` and returns a list of 5 elements. It creates an overall impression of how the reference signature aligns with the comparison signature at the congruent registration position.

*   The first element is a plot called `segment_shift_plot`, which is shown in \autoref{fig:sigplot}. On this plot only the congruent matching profile segments are plotted along with the comparison signature at the congruent registration position. 

<!-- basis segments that agree with the congruent registration position (i.e. the segments that are congruent matching profile segments) are plotted along with the comparison signature. When plotting, each of those basis segments will be shifted to the position where the basis segment obtains a cross-correlation peak and is within the tolerance zone of the congruent registration position. -->

*   The second element is a plot called `signature_shift_plot`, which is shown in \autoref{fig:sigplot2}. On this visual both the reference signature and the comparison signature are plotted. The reference signature is aligned with the comparison signature based on the congruent registration position. And the congruent matching profile segments are highlighted with solid lines. 

\begin{figure}[hbt]
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:sigplot}The black line shows the comparison signature; each red line segment shows one congruent matching profile segment.}
```{r sigplot, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
sig.plot <- cmps_signature_plot(
  cmps_with_multi_scale
)
sig.plot$segment_shift_plot
```
\end{subfigure}
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:sigplot2}The black line shows the comparison signature; the red line shows the reference signature. Solid part shows the congruent matching profile segments, and the dashed part shows segments that do not agree with the congruent registration position.}
```{r sigplot2, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
sig.plot$signature_shift_plot
```
\end{subfigure}
\caption{\label{fig:sigplots} Two visual outputs of cmps\_signature\_plot()}
\end{figure}

*   Other elements of this list are `seg_shift` and `sig_shift`. `sig_shift` gives the congruent registration position, while `seg_shift` is a data frame showing the congruent matching profile segments and their identified candidate position closest to the congruent registration position.

```{r, echo=TRUE, eval=TRUE}
sig.plot$seg_shift
```

<!-- These elements are essentially used for generating visuals above but also provide insights about the congruent registration position and the candidate positions found by each of the congruent matching profile segments.  -->
<!-- which basis segments are the congruent matching profile segments. -->

As `cmps_signature_plot()` focuses on the signature level, on the other hand, `cmps_segment_plot()` focuses on the segment level. It not only takes the "full result" of `extract_feature_cmps()`, but also takes an argument `seg.idx`, indicating which segment to be inspected. As shown in \autoref{fig:segplots}, for example, after checking `sig.plot$seg_shift` we noticed that segment 6 is not one of the congruent matching profile segments. So we can set `seg.idx = 6` in order to take a closer look at segment 6 and understand the reason why it disagrees with the congruent registration position. `cmps_segment_plot()` also returns a list, of which each element corresponds to one segment scale of this basis segment. Then at each segment scale, we will have two plots, `segment_plot` and `scale_ccf_plot`. 

*   \autoref{fig:segplot} is the `segment_plot` of basis segment 6 at scale one (its original scale). Since when computing the CMPS score we used `npeaks.set = c(5, 3, 1)` in `extract_feature_cmps()`, 5 peaks are identified in the cross-correlation curve at scale one, and segment 6 at scale one is plotted at the positions where these 5 peaks are identified with dashed lines in the `segment_plot`. 

<!-- Take the first element of `seg.plot` as an example, it corresponds to the first segment scale (the original scale) of the 6th basis segment and carries two plots, `segment_plot` and `scale_ccf_plot`. -->
<!-- Remember that when computing the CMPS score, we were using `npeaks.set = c(5, 3, 1)`. This means that for the first segment scale, 5 peaks are identified in the cross-correlation curve. `segment_plot` plots the 6th basis segment in its first scale at its original position as well as the positions where the basis segment obtains its 5 cross-correlation peaks.  -->

*   \autoref{fig:segplot2} is the `scale_ccf_plot` of basis segment 6 at scale one. It shows the cross-correlation curve computed by the comparison signature and the scale-one basis segment 6. The five highest peaks are marked by dots on the curve.

\begin{figure}
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:segplot}segment\_plot for segment 6 at scale 1. The original position of segment 6 is indicated by the solid black line. Positions where the segment achieves the 5 highest cross-correlations are indicated by the dashed line segments.}
```{r segplot, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
seg.plot <- cmps_segment_plot(
  cmps_with_multi_scale, 
  seg.idx = 6
)
seg.plot[[1]]$segment_plot
```
\end{subfigure}
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:segplot2}scale\_ccf\_plot shows the cross-correlation curve between the comparison signature and segment 6 at scale 1. The five highest peaks are marked by dots. The vertical red dashed line indicates the congruent registration position; the green dashed line shows a peak position in its highest segment scale; the blue dashed lines show the tolerance zone around the green dashed line. We can see here none of the five highest peaks at scale one is within the tolerance zone, indicating that there is no consistent correlation peak or a candidate position identified by basis segment 6 under the multi segment lengths strategy. Thus, the basis segment 6 doesn't vote for the congruent registration position and is not a cmps.}
```{r segplot2, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
seg.plot[[1]]$scale_ccf_plot
```
\end{subfigure}
\caption{\label{fig:segplots} Two plots used to investigate basis segment 6 at scale one}
\end{figure}

Additionally, users can have more insights about why segment 6 is not a congruent matching profile segment if we put the `segment_plot` and `scale_ccf_plot` of all three segment scales together, as shown in \autoref{fig:seg_all} with the help of `ggpubr::ggarrange()`.

\begin{figure}
```{r segplot3, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
library(ggpubr)

ggarrange(
  plotlist = 
    unlist(seg.plot, 
           recursive = FALSE),
  ncol = 2, 
  nrow = 3)
```
\caption{\label{fig:seg_all} Put segment\_plot and scale\_ccf\_plot of all three scales together. We are identifying five highest peaks at scale one, three peaks at scale two, and one peak at scale three since npeaks.set = c(5, 3, 1). The highest peak position at scale three is marked by the green dashed line across all segment scales, but it doesn't achieve the top five highest peaks at scale one, indicating that there is no consistent correlation peak or a candidate position for basis segment 6 under the multi segment lengths strategy.}
\end{figure}

<!-- ```{r, echo=FALSE, out.width="400px", fig.cap="put segment\\_plot and scale\\_ccf\\_plot of all scales together. We are identifying five highest peaks at scale 1, three peaks at scale 2, and one peak at scale 3 since npeaks.set = c(5, 3, 1). Putting these plots together can help better understand why segment 6 is not a congruent matching profile segment. Here we can also see clearly that increasing segment length can reduce the number of false positive peaks."} -->
<!-- knitr::include_graphics("img/segplot3.png", dpi = 100) -->
<!-- ``` -->

In \autoref{fig:seg_all}, the red vertical dashed line indicates the congruent registration position. We can see that the basis segment 6 does obtain a peak near the congruent registration position at scale two and scale three, respectively; however, this position doesn't give one of the five highest peaks at scale one. As a result, segment 6 fails to identify the consistent correlation peak (ccp) and fails to become one of the congruent matching profile segments according to the multi segment lengths strategy. The identified top five peaks at scale one are also examples of "false positive" peaks. The "true positive" peak (the peak within the tolerance zone of the congruent registration position) is identified at scale two and three by increasing the segment length, which justifies the usage of multi segment lengths strategy.

## Results

**Metrics Based on CMPS scores**

```{r hamby252-data, eval=TRUE, echo=FALSE}
# for hamby 252
N <- 3
CMPS_hamby252_results <- list()
CMPS_hamby252_results$span1 <- list(0.75, 0.25, 0.25)
CMPS_hamby252_results$signame <-
  list("sigs75", "sigs25", "sigs25_1062")
CMPS_hamby252_results$npeaks.set <-
  list(c(5, 3, 1),
       c(5, 3, 1),
       c(10, 6, 2))
CMPS_hamby252_results$seg_length <- list(50, 50, 50)
CMPS_hamby252_results$Tx <- list(25, 25, 25)
CMPS_hamby252_results$titlee <- list()
CMPS_hamby252_results$filename <- list()
for (i in 1:N) {
  CMPS_hamby252_results$titlee[[i]] <-
    paste0(
      "npeaks.set=c(",
      paste(CMPS_hamby252_results$npeaks.set[[i]], collapse = ","),
      ")",
      ", span1=",
      CMPS_hamby252_results$span1[[i]],
      ", span2=0.03, len=",
      CMPS_hamby252_results$seg_length[[i]],
      ", Tx=",
      CMPS_hamby252_results$Tx[[i]]
    )
  CMPS_hamby252_results$filename[[i]] <- 
    paste(
      "hamby252",
      CMPS_hamby252_results$span1[[i]]*100,
      paste(CMPS_hamby252_results$npeaks.set[[i]], collapse = "-"),
      CMPS_hamby252_results$seg_length[[i]],
      CMPS_hamby252_results$Tx[[i]],
      sep = "_"
    )
}
CMPS_hamby252_results$cmps.table <- list()
CMPS_hamby252_results$plot <- list()

for(i in 1:N){
  CMPS_hamby252_results$cmps.table[[i]] <- 
  read.csv(file = paste("./data/", 
                        CMPS_hamby252_results$filename[[i]], 
                        ".csv",
                        sep = ""))
}

# generate plots
for (i in 1:3) {
  hamby252.cmps <- CMPS_hamby252_results$cmps.table[[i]]
  
  hamby252.plot.list <- list()
  titlee <- CMPS_hamby252_results$titlee[[i]]
  
  hamby252.plot.list[[1]] <- hamby252.cmps %>% ggplot() +
    geom_histogram(aes(x = cmps.max.m,
                       fill = as.factor(type_truth)), binwidth = 1) +
    labs(
      fill = "Comparison Type",
      x = expression(CMPS[max]),
      title = expression(paste("Hamby252 - ", CMPS[max], " Distribution")),
      subtitle = titlee
    ) +
    scale_x_continuous(breaks = seq(0, 27, 1)) +
    theme_bw() +
    theme(panel.grid.minor = element_blank()) 
    
  
  hamby252.plot.list[[2]] <- hamby252.cmps %>% ggplot() +
    geom_histogram(aes(x = cmps.maxbar.m,
                       fill = as.factor(type_truth)), binwidth = 1) +
    labs(
      x = expression(bar(CMPS)[max]),
      fill = "Comparison Type",
      title = expression(paste(
        "Hamby252 - ", bar(CMPS)[max], " Distribution"
      )),
      subtitle = titlee
    ) +
    scale_x_continuous(breaks = seq(0, 24, 1)) +
    theme_bw() +
    theme(panel.grid.minor = element_blank()) 
  
  plot <- ggarrange(plotlist = hamby252.plot.list,
                    nrow = 1,
                    ncol = 2)
  CMPS_hamby252_results$plot[[i]] <- plot
}

```

```{r, eval=TRUE, echo=TRUE, fig.height=3}
CMPS_hamby252_results$plot[[1]]
```


```{r hamby44-data, eval=TRUE, echo=FALSE}
N <- 3
CMPS_hamby44_results <- list()
CMPS_hamby44_results$span1 <- list(0.25, 0.25, 0.75)
CMPS_hamby44_results$signame <-
  list("sigs25_531", "sigs25_1061", "sigs75_531")
CMPS_hamby44_results$npeaks.set <-
  list(c(5, 3, 1),
       c(10, 6, 1),
       c(5, 3, 1))
CMPS_hamby44_results$seg_length <- as.list(rep(61, 3))
CMPS_hamby44_results$Tx <- as.list(rep(30, 3))
CMPS_hamby44_results$titlee <- list()
CMPS_hamby44_results$filename <- list()
for (i in 1:N) {
  CMPS_hamby44_results$titlee[[i]] <-
    paste0(
      "npeaks.set=c(",
      paste(CMPS_hamby44_results$npeaks.set[[i]], collapse = ","),
      ")",
      ", span1=",
      CMPS_hamby44_results$span1[[i]],
      ", span2=0.03, len=",
      CMPS_hamby44_results$seg_length[[i]],
      ", Tx=",
      CMPS_hamby44_results$Tx[[i]]
    )
  CMPS_hamby44_results$filename[[i]] <- 
    paste(
      "hamby44",
      CMPS_hamby44_results$span1[[i]]*100,
      paste(CMPS_hamby44_results$npeaks.set[[i]], collapse = "-"),
      CMPS_hamby44_results$seg_length[[i]],
      CMPS_hamby44_results$Tx[[i]],
      sep = "_"
    )
}
CMPS_hamby44_results$cmps.table <- list()
CMPS_hamby44_results$plot <- list()
```


As presented in the work of @cmps, researchers applied the CMPS method to one of the Hamby set scans (Hamby 252). In order to show that our implementation of the CMPS algorithm is able to reproduce the results in @cmps and be used for other data sets, we applied our implementation to both Hamby set 252 and Hamby set 44. Since the CMPS algorithm works with, in our case, bullet signatures, we conducted some data-processing. For both Hamby 252 and Hamby 44, we started with x3p files in the database, followed the framework proposed by Hare and Hofmann [@aoas] with the same set of parameters, removed damaged bullet scans, obtained bullet signatures for each bullet land engraving, and removed outliers in bullet signatures. Note that in the work of @cmps they used a different framework to obtain bullet signatures. However, since the work of @cmps is not open-source, we were not able to follow their framework and were only able to reproduce the results for Hamby set 252 qualitatively.

The CMPS score can be considered as a similarity score of two signatures. Then how can we get a similarity score of two bullets based on CMPS scores (each bullet consists of six bullet signatures in our case)? In @cmps researchers introduced two similarity metrics, $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$, for bullet-level comparisons. $\mathrm{CMPS_{max}}$ is the highest CMPS score obtained among all pairwise bullet signature comparisons. And $\mathrm{\overline{CMPS}_{max}}$ is the highest possible mean CMPS score of signature comparisons that are in the same phase.

We can continue with the example used in previous sections. `bullets` contains bullet signatures of two bullets, `bullet1` and `bullet2`. As mentioned before, each bullet has six land engravings, resulting in six bullet signatures. Thus, there are 36 pairwise bullet signature comparisons in total. We compute the CMPS scores for all 36 comparisons using multi segment lengths strategy with default parameters, and the result is shown in \autoref{fig:tiles}

```{r tiles, echo=FALSE, fig.cap="CMPS scores of all 36 pairwise bullet signature comparisons for two bullets", out.width=".7\\textwidth", fig.align="center"}
dframe <- dframe %>% mutate(
  landA = paste0("L", landA),
  landB = paste0("L", landB),
  landB = factor(landB, levels = paste0("L", c(2:6,1))),
  bulletA = paste0("Bullet ", bulletA),
  bulletB = paste0("Bullet ", bulletB)
)

dframe %>% ggplot(aes(x = landA, y = landB, fill = cmps_score)) + 
  geom_tile() + 
  geom_tile(aes(colour="same barrel"), fill=NA, data = dframe %>% filter(samesource), size=1) + 
  scale_fill_gradient2("CMPS score", low = "gray80", high = "darkorange", midpoint = 6) + 
  scale_colour_manual("Source", values="darkorange") +
  facet_grid(bulletB ~ bulletA) + xlab("Bullet1 Lands") + 
  ylab("Bullet2 Lands") + theme(aspect.ratio = 1) +
  geom_text(aes(label=cmps_score)) +
  theme_bw() +
  theme(aspect.ratio = 1)
```


<!-- based on CMPS scores of bullet signature comparisons. For example, there are in total 6 $\times$ 6 signature comparisons in order to compare two bullets in Hamby study since each bullet has 6 LEAs and each LEA generates a bullet signature. And a CMPS score will be found for every signature comparison. $\mathrm{CMPS_{max}}$ is the highest CMPS score among all signature comparisons. And $\mathrm{\overline{CMPS}_{max}}$ is the highest possible average CMPS score of signature comparisons that are in the same phase. -->

<!-- Here are the CMPS scores of all 36 signature comparisons of the bullets in the example above. -->

<!-- ```{r} -->
<!-- #      [,1] [,2] [,3] [,4] [,5] [,6] -->
<!-- # [1,]    2    3    2    3    1    2 -->
<!-- # [2,]    2    1   17    1    2    3 -->
<!-- # [3,]    1    1    3   14    2    2 -->
<!-- # [4,]    2    1    1    1   10    1 -->
<!-- # [5,]    2    2    1    1    1   15 -->
<!-- # [6,]   16    3    1    2    1    1 -->
<!-- ``` -->

In this example, $\mathrm{CMPS_{max}}$, the highest CMPS score, is 17, and $\mathrm{\overline{CMPS}_{max}}$, the highest possible mean CMPS score of comparisons in the same phase, is $(3+17+14+10+15+16)/6=12.5$. 

**Hamby 252**

Figure 2 shows the distribution of $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$ after we applied the CMPS algorithm to Hamby set 252. Although the CMPS scores we found here are not exactly the same as those presented in @cmps since we don't have the exact parameters and functions used by the researchers, the results we obtained are promising. For both $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$ we can observe a clear separation between the known matching comparisons (KM) and known non-matching comparisons (KNM). Table x shows some summary statistics. 

The parameters we used in `extract_feature_cmps` are:

```{r, eval=FALSE}
extract_feature_cmps(
  x, y,
  seg_length = 50,
  Tx = 25,
  npeaks.set = c(5,3,1),
  include = "nseg"
)
```

Note that for Hamby set 44, one unit represents 1.5625 \textmu m so setting `seg_length = 50` makes each basis segment have length 78.125 \textmu m. And `Tx = 25` makes the tolerance zone be $\pm 39.0625$ \textmu m. This is to mimic the parameters used in the [original paper].

<!-- this is figure 2 -->
```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 252; removed outliers; seg\\_length = 50, Tx = 25, npeaks.set = c(5,3,1) "}
# [4] "span1=0.25, span2=0.03, rm_outliers = TRUE, 5025, 531"  
knitr::include_graphics("img/hamby252_v1.png", dpi = 100)
```

table 1:

```{r, echo=FALSE, warning=FALSE}
# rtt <- readRDS("summary_table.rds")
# colnames(rtt) <- 
rtt <- data.frame(parameters = c("span1=0.25, (5, 3, 1)", "span1=0.25, (10, 6, 1)", "span1=0.75, (5, 3, 1)"),
                  p1 = c(7,9,6),
                  p2 = c(10, 13, 11),
                  p3 = c(3.6, 4.833, 3.167),
                  p4 = c(6.667, 9.167, 6.6))
colnames(rtt) <- c("Parameters",
                   "$\\mathrm{CMPS_{max}}$ KNM's max",
                   "$\\mathrm{CMPS_{max}}$ KM's min",
                   "$\\mathrm{\\overline{CMPS}_{max}}$ KNM's max",
                   "$\\mathrm{\\overline{CMPS}_{max}}$ KM's min")

knitr::kable(rtt, "latex", booktabs = TRUE, escape = FALSE,
             caption = "min and max of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ showing the separation between KNM and KM",
             row.names = FALSE, digits = 4) %>% 
  column_spec(2:5, width = "2cm")
```



Figure 3 shows the results for Hamby set 44. Again, we are able to see a clear separation between the KM comparisons and the KNM comparisons, but it would be better if the separation can be further enlarged. Table 1 shows some summary statistics for Hamby set 44. 

For Hamby set 44, the parameters we used in `extract_feature_cmps` are:

```{r, eval=FALSE}
extract_feature_cmps(
  x, y,
  seg_length = 61, 
  Tx = 30,
  npeaks.set = c(5,3,1),
  include = "nseg"
)
```

Note that we used different values here for `seg_length` and `Tx` because our Hamby set 44 scans have a different scanning resolution. One unit here represents 1.29 \textmu m. So here each basis segment has length 78.69 \textmu m, and the tolerance zone is $\pm 38.7$ \textmu m.

<!-- this is figure 3 -->

```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 44; removed outliers; seg\\_length = 61, Tx = 30, npeaks.set = c(5,3,1), span1=0.25"}
# [1] "span1=0.25, span2=0.03, rm_outliers"
knitr::include_graphics("img/hamby44_v1.png", dpi = 100)
```

Figure 4 shows another Hamby set 44 results, but the parameter `npeaks.set` is now `c(10, 6, 1)`. We can see that the separation between KM comparisons and KNM comparisons is increased. This shows that the parameters used in the CMPS algorithm can affect the CMPS results, and an open-source implementation of the algorithm will facilitate efforts of cross-validating these parameters.

<!-- this is figure 4 -->

```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 44; removed outliers; seg\\_length = 61, Tx = 30, npeaks.set = c(10,6,1), span1=0.25 "}
# [5] "span1=0.25, span2=0.03, rm_outliers, c(10,6,1)"
knitr::include_graphics("img/hamby44_c1_v1.png", dpi = 100)
```

For the results above we used `span1=0.25` in the function `cc_get_signature` when computing the signatures; however, in this example we used `span1=0.75` and changed the characteristic of those signatures. As we can see in figure 5, this change also affects the CMPS results.

<!-- this is figure 5 -->

```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 44; removed outliers; seg\\_length = 61, Tx = 30, npeaks.set = c(5,3,1), span1=0.75"}
# [4] "span1=0.75, span2=0.03, rm_outliers"  
knitr::include_graphics("img/hamby44_c2_v1.png", dpi = 100)
```

[The codes generating those results can be found in the appendix. ???]


## Conclusion

We presented the CMPS package, an open-source implementation of the congruent matching profile segments (CMPS) algorithm. The CMPS algorithm was proposed by NIST in 2019 and was made for objective tool marks comparisons. In this paper, functions included in the package were illustrated along with the basic logic of the CMPS algorithm. 
And we used a small dataset included in the package as an example to explain the usage of the package. Some graphing tools were also implemented in the package so that users can visualize results and have a better understanding of both the algorithm and the results. We also applied the algorithm to two datasets in Hamby study (Hamby set 252 and Hamby set 44), and the results we obtained were promising. 

From the results of both Hamby set 252 and 44, we can see that the CMPS scores of KM comparisons computed by `extract_feature_cmps` were able to be separated from those of KNM comparisons. And at the same time, we can see that CMPS algorithm is sensitive to the choice of parameters such as segment length, number of peaks detected at each segment scale, and congruency tolerance. Some parameter choices are better in the sense that they can enlarge the separation between the KM comparisons and the KNM comparisons. And the best set of parameters depend on the dataset being used, and the choice of parameters has not been, but should be, cross-validated. 

Our open-source implementation introduces the CMPS algorithm to R community and allows everyone to use it for their own projects. It would also facilitate future studies on parameter cross-validation and the development of statistical methods to modeling KM and KNM CMPS score distributions.  

<!-- open source -->
<!-- module -->
<!-- hamby 44 new data set -->
<!-- hamby 252 -->
<!-- threshold -->


### About this format and the R Journal requirements

`rticles::rjournal_article` will help you build the correct files requirements: 

* A R file will be generated automatically using `knitr::purl` - see
https://bookdown.org/yihui/rmarkdown-cookbook/purl.html for more information.
* A tex file will be generated from this Rmd file and correctly included in
`RJwapper.tex` as expected to build `RJwrapper.pdf`.
* All figure files will be kept in the default rmarkdown `*_files` folder. This
happens because `keep_tex = TRUE` by default in `rticles::rjournal_article`
* Only the bib filename is to modifed. An example bib file is included in the
template (`RJreferences.bib`) and you will have to name your bib file as the
tex, R, and pdf files.
