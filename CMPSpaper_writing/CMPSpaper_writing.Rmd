---
title: Capitalized Title Here
header-includes:
  - \usepackage{xcolor}
author:
  # see ?rjournal_article for more information
  - name: Author One
    affiliation: Affiliation
    address:
    - line 1
    - line 2
    url: https://journal.r-project.org
    orcid: 0000-0002-9079-593X
    email:  author1@work
  - name: Author Two
    url: https://journal.r-project.org
    email: author2@work
    orcid: 0000-0002-9079-593X
    affiliation: Affiliation 1
    address:
    - line 1 affiliation 1
    - line 2 affiliation 1
    affiliation2: Affiliation 2
    address2:
    - line 1 affiliation 2
    - line 2 affiliation 2
  - name: Author Three
    url: https://journal.r-project.org
    email: author3@work
    affiliation: Affiliation
    address:
    - line 1 affiliation
    - line 2 affiliation
abstract: >
  An abstract of less than 150 words.
preamble: |
  % Any extra LaTeX you need in the preamble
  
# per R journal requirement, the bib filename should be the same as the output 
# tex file. Don't forget to rename the bib file and change this example value.
bibliography: RJreferences.bib

output: rticles::rjournal_article
---


```{=tex}
\newcommand{\hh}[1]{{\textcolor{orange}{#1}}}
\newcommand{\wj}[1]{{\textcolor{blue}{#1}}}
\setlength{\parindent}{0pt}
```

## Introduction

\hh{Will, it might be better to put the focus of the paper on the open-source implementation of the CMPS algorithm, rather than the examination of bullets. You also need to make sure to state early and often that you are not claiming that this algorithm is your idea. You are implementing the algorithm described in the paper by NIST researchers. }

In this paper we present an open-source implementation of the algorithm of the Congruent Matching Profile Segments (CMPS) method. @cmps developed the CMPS method for "objective comparison of striated tool marks" and demonstrated its usage in examples of comparing bullet signature correlations. Although @cmps introduced the algorithm of the CMPS method in their paper, an open-source implementation of this powerful method was missing. Thus, our effort here is to introduce the CMPS method to `R` community and provide an open-source implementation of the algorithm for people to use and make further improvements. Our implementation was wrapped up into a `R` package called `CMPS`, which is available on GitHub[cite git?]. In the following sections we will: review the background of bullet signature comparisons, discuss how we followed the idea described by @cmps and implemented the CMPS algorithm, and present results of applying our implementation to real data. 





## Background 

An important task of firearm examination is \hh{to answer the question of whether wo pieces of evidence come from the same source or whether a piece of evidence matches a sample obtained from a specific firearm. Here, in particular, we are interested } to determine whether two bullets were fired from the same gun barrel. 
\hh{Assessing the similarity between two bullets is based on a comparison of their striation marks acquired during the firing process as bullets are propelled through the barrel. }
It is achievable because lands in a gun barrel create striation marks on the bullet during the firing process, and it is believed that the same gun barrel will create highly similar striation marks on the bullets it fired. Typically the striation marks are created by lands in a barrel, so the striation marks are also sometimes refered as land engravings, and the areas the marks occupy are called land engraved areas (LEA). Firearm examination has been playing an important role in terms of convictions in the United States criminal justice system. However, in recent years people became more cautious about firearms identification, and criticism of its subjective methodology arose. A report published by the National Academy of Sciences in 2009 states that "[m]uch forensic evidence-including, for example, bite marks and firearm and toolmark identification—is introduced in criminal trials without any meaningful scientific validation, determination of error rates, or reliability testing to explain the limits of the discipline." To overcome those critics and concerns, people have been making an effort to build databases and develop frameworks and algorithms that can bring an objective and quantitative assessment into the field. The bullet signatures extracted from the bullet are important in this process since they can well describe the striation marks on the bullet and can well be understood by algorithms.

The datasets we worked with come from the James Hamby Consecutively Rifled Ruger Barrel Study [@brundage; @hamby; @Hamby:2019], and in particular, they are Hamby set 252 and Hamby set 44. For each Hamby set in the study, 35 bullets are fired by ten Ruger P-85 pistol barrels. 20 of the 35 bullets are known test bullets and 15 of them are unknown bullets. Each bullet has six land engraved areas (LEA) or land impressions, whose 3D topographical images were obtained and stored in the x3p format (XML 3-D Surface Profile). The x3p format provides a standard way of exchanging 2D and 3D profile data. It conforms to the ISO5436-2 standard [http://sourceforge.net/p/open-gps/mwiki/X3p/] and was adopted by the OpenFMC (Open Forensic Metrology Consortium), a group of firearm forensics researchers who contributes to the establishment of best practices of using metrology in forensic science. Hamby set 252 were scanned using a NanoFocus lens at 20x magnification with the scan resolution being 1.5625 \textmu m $\times$ 1.5625 \textmu m per pixel. Hamby set 44 were scanned ...[at CSAFE?]... Both Hamby set 252 and Hamby set 44 are publicly available on the NIST Ballistics Database Project.

The automated framework  used in this paper was proposed by @aoas. In order to obtain bullet signatures from the x3p files of bullet land impressions, we used `R` packages `x3ptools`[cite?] and `bulletxtrctr`[cite?]. `x3ptools` can be used to process x3p files. In the case of Hamby set 252, we need to convert the measurements of x3p files from meters to microns (`x3ptools::x3p_m_to_mum`) and rotate x3p files to make the long axis horizontal (`x3ptools::x3p_rotate`). Figure 1(a) shows a bullet land impression scan of a processed x3p file. The raised portion of the surface are groove impressions, and the vertical striation marks between the groove impressions are what we are interested in, called a land impression. The first step of obtaining the bullet signature is to extract a cross-section at a fixed height along the land impression. `bulletxtrctr::x3p_crosscut_optimize` can be used to determine an ideal height, and `bulletxtrctr::x3p_crosscut` can be used to acquire the crosscut data (`ccdata`). Figure 1(c) shows the typical pattern of the crosscut data, where "wedges" can be found on the left and right side and indicate the boundary between the land impression and the groove impression. `bulletxtrctr::cc_locate_grooves` is used to locate and chop these wedge areas so that only the curve of the land impression in the middle is kept. With the groove impressions excluded, we then use `bulletxtrctr::cc_get_signature` to smooth out the land impression curvature using LOESS (locally estimated scatter plot smoothing) [Cleveland 1979?] and obtain the bullet signature. Figure 1 illustrates this framework. Sometimes the algorithm in our framework cannot determine the ideal location of the crosscut or the grooves due to the deformation of a bullet, so we also developed a `R` Shiny App called `bulletinspectR` to identify and correct those errors. Note that NIST researchers used a different way of getting the bullet signatures in their paper [cite?].

```{r, echo=FALSE, out.width="400px", fig.cap="image of a XXX gun barrel and a fired bullet"}
knitr::include_graphics("img/barrel_bullet.PNG", dpi = 100)
```

```{r, echo=FALSE, out.width="400px", fig.cap="figure captions \\hh{it'd be also good to put in labels for each state. I've added a huge arrow to help with the directionality (Stacy said she had trouble) - I like the way you have the order, it might just need some emphasis. What do you think of adding a bigger arrow (or arrows) in the back?} (a) front view of a scanned land engraved area (LEA). The optimized crosscut location is indicated by the white line. (b) view of the cross-section of the land engraved area at the white line in (a). (c) the crosscut data plotted in 2D; blue vertical lines indicate the position of left and right grooves (d) the crosscut data after chopping the left and right grooves (e) the fitted curvature using LOESS (f) after removing the curvature from the crosscut data, the bullet signature is obtained"}
knitr::include_graphics("img/figure1_v2.PNG", dpi = 100)
```

Once we obtain the bullet signatures, we can compare them using an algorithm that computes a similarity score. The congruent matching profile segments (CMPS) algorithm, developed by NIST for "objective comparison of striated tool marks" [@cmps], is one such algorithm. The main idea of the CMPS algorithm is that, we cut the reference profile (one of the two bullet signatures) into consecutive and non-overlapping basis segments and ask each basis segment to find the "best" registration position on the comparison profile (the other bullet signature) in terms of correlation values. Then the congruent registration position is the position where the most basis segments find it the "best", and the number of basis segments taking the congruent registration position is the CMPS score. The CMPS algorithm can assist firearm examiners with drawing a conclusion, but NIST's implementation of the CMPS algorithm was not released for the public. Thus, in this paper we present an open-source implementation of the CMPS algorithm so that everyone can use and improve it. With our implementation, one can compute the CMPS score of a comparison using the following code:

```{r, eval=FALSE}
cmps.result <- extract_feature_cmps(sig1, sig2)
```

In the example in section "Implementation" we would see that, two bullet signatures coming from the same source get a CMPS score of X, while two signatures coming from different sources get a CMPS score of Y. We also implemented graphing tools for users to better understand these results as well as the algorithm itself.

The section "Implementation" will go through the algorithm and show how to use the "CMPS" package. An example that illustrates the main points are also included. The section "Results" presents the results of evaluating the CMPS package using Hamby set 252 and Hamby set 44. And the last section covers some final discussion and conclusions.


## Implementation

**Algorithm.** 

The CMPS algorithm consists of X steps.   

step 1) cut the reference profile into consecutive, non-overlapping and equal-length basis segments;

`get_segs(x, len=50)` implements the first step. It takes a profile in the format of a numeric vector and cuts it into consecutive, non-overlapping and equal-length segments of length `len`.

step 2) each basis segment finds its best registration position on the comparison profile. A cross-correlation curve between a basis segment and the comparison profile would be computed, and a registration position is considered as "good" if the basis segment achieves a high cross-correlation value at this position. 

Then how should a basis segment find its best registration position? [In the original paper] researchers proposed two versions of the CMPS alrorithm that can answer this question. The first version is called "multi-peak inspection", and the second version is called "multi-peak inspection at different segment lengths/scales". We also refer the second version as the CMPS algorithm using "the multi segment lengths strategy".

Step 2.1) multi-peak inspection: each basis segment identifies positions of 5 (or multiple) highest peaks in the cross-correlation curve. Since false positive peaks would stand out when the segment length is short, positions of all 5 peak will be considered as the potential "best" registration position.

Step 2.2) multi segment lengths strategy: for this version of the CMPS algorithm, each basis segment finds only one "best" registration position. This "best" registration position can be found by conducting multi-peak inspection multiple rounds. The first round is the standard way as we have stated in step 2.1. But after the first round, we will increase the segment length, compute a new cross-correlation curve, and again identify multiple peaks in the cross-correlation curve. The number of peaks identified in this round is typically less than that in the previous round (say 3 highest peaks) since increasing the segment length can reduce the number of false positive peaks. We can repeat this procedure multiple times; however in the last round, only one highest peak should be identified. If a position can be identified for all different segment length, this position will be selected as the "best" registration position and is called the "consistent correlation peak" (ccp).


<!-- we conduct the "multi-peak inspection at different segment lengths". After having the multi-peak inspection for a basis segment of its original length, we then double the segment length by including profiles of half the current length -->


<!-- If the reference profile and the comparison profile matches perfectly, every basis segment should vote for exactly the same registration position.  -->

<!-- compute the cross-correlation function between each basis segment and the comparison profile; -->

`get_ccf4` computes the cross-correlation function / correlation coefficient curve between two profiles. This is the function called whenever we need to compute the ccf.

<!-- step 3) if the multi segment lengths strategy is being used, each basis segment would increase its length and compute a new cross-correlation function with the comparison profile in order to identify a potential “consistent correlation peak”; if the multi segment lengths strategy is not being used, each segment would then find 5 peaks in its cross-correlation function; -->

`get_seg_scale` takes a basis segment and increases its segment length. `scale=1` gives the original length of the basis segment. Increasing `scale` by 1 will double the segment length.

`get_ccr_peaks` takes a segment and the comparison profile, then computes the correlation coefficient curve between them and finds peaks on the correlation coefficient curve. The number of peaks detected is equal to `npeaks`. And we are using `rollapply` to find peaks on the curve effectively.

`get_ccp` checks if the "consistent correlation peak" exists under the framework of multi segment lengths strategy. Since we are requiring the highest segment scale identifies only one peak, we just need to check if this peak shows any "consistency". In other words, we check if this peak is also identified as a peak in other segment scales. 

step 3) determine the congruent registration position with a small tolerance zone and the number of basis segments that take the congruent registration position as their "best" registration position. These segments are called the "congruent matching profile segments" (CMPS), and the number of CMPS is the CMPS score of this profile comparison.

`get_CMPS` considers all basis segments and their identified peak positions to determine the congruent registration position. The goal is to find a peak position that is agreed by the most basis segments. Since small errors are allowed, a tolerance zone would serve as a selection window. `get_CMPS` will move this selection window from left to right and go through all possible positions and check the number of basis segment that identifies a peak in the selection window for each position. Since we are moving this tolerance zone from left to right one unit a time, some consecutive positions are expected to have the same number of basis segments. [?.?]In that case the median of all tied and consecutive positions will be chosen as the congruent registration position. As long as the congruent registration position is determined, the number of basis segments that identify a peak in this position is the CMPS score.

Note that there are parameters in this algorithm that can be specified by the users to conform the structure of their data, such as the length of basis segments in step 1, the number of peaks identified in step 3, and the length of the tolerance zone in step 3. In our implementation of the CMPS algorithm we took the original CMPS paper [cite?] as the reference to determine the default values of these parameters. 
The main function that follows the CMPS algorithm is called `extract_feature_cmps`. It consists of all steps of the algorithm and receives parameters from the users. 

* `seg_length` specifies the length of basis segments [(in mm?)] mentioned in step 1; 
* `npeaks.set` determines the number of peaks and whether the function uses the multi segment lengths strategy. If `npeaks.set` is a numeric vector of length 1, for example `npeaks.set = c(5)`, then the function will not use multi segment lengths and find 5 peaks in the correlation coefficient curve for each basis segment; on the other hand, if the vector length of `npeaks.set` is larger than 1, for example `npeaks.set = c(5, 3, 1)`, the function will take advantage of the multi segment lengths strategy, finding 5 peaks in the original scale, 3 peaks in the second scale and 1 peak in the third scale. Note that if the multi segment lengths strategy is being used, the last element of `npeaks.set` should always be 1. 
* `Tx` gives the size of tolerance zone mentioned in step 4;
* `include` determines what information should be included in the function output. By default, `include = NULL` and the function output will only contain the `CMPS.score`. However, besides the most important `CMPS.score`, there are other pieces of information related to the CMPS score that one might be interested in, such as 
  - `nseg`: the number of basis segments we get from the reference profile; this is also the highest possible CMPS score of the comparison;
  - `congruent.pos`: the congruent registration position;
  - `congruent.seg.idx`: the indices of all basis segments that agree with the congruent registration position;
  - `segments`: the list of basis segments used for the computation of CMPS score;
  - `parameters`: all inputs of `extract_feature_cmps`
For all possible options of `include`, please check the documentation of `extract_feature_cmps` or using `?extract_feature_cmps`. If we want everything to be included in the output, we can use `include = full_result`. These additional pieces of information are helpful in terms of understanding how we obtained such CMPS score. 
  


[examples https://journal.r-project.org/archive/2019/RJ-2019-044/RJ-2019-044.pdf]
[https://journal.r-project.org/archive/2019/RJ-2019-002/RJ-2019-002.pdf]


**Install**

The CMPS package is/not published on CRAN, and can be install and called by 

```{r, eval=FALSE}
install.packages(CMPS)
```

The development version can be installed by using 

```{r, eval=FALSE}
# install.packages("devtools") 
devtools::install_github("willju-wangqian/CMPS")
```

**Examples**

The `CMPS` package contains a simple example to illustrate the basic usage of the package. The data in this example are twelve bullet signatures obtained from two bullets in Hamby set 252 [cite?] (Each bullet has six lands). The procedure for generating signatures from 3D bullet lands in x3p format is (algorithmic) [and has been discussed above]. And these two bullets are known to come from the same gun barrel, so for the 36 land-by-land comparisons, 6 of them are KM (known matching) comparisons and 30 are KNM (known non-matching) comparisons. To access the example data, one can use

```{r, eval=FALSE}
library(CMPS)
data(bullets)
```

And anyone who is interested in the data source can find it in `bullets$source`. One can use these links to download the original x3p files from [NIST, cite?]. `bulletxtrctr::read_bullet(urllist = bullets$source)`

**extract_feature_cmps**

`extract_feature_cmps` integrates all steps of the CMPS algorithm. It takes two bullet profiles and computes the CMPS score. 

```{r, eval=FALSE}
extract_feature_cmps(
  x,
  y,
  seg_length = 50,
  Tx = 25,
  npeaks.set = c(5, 3, 1),
  include = NULL
)
```

The comparison between "bullet 1 - land 2" and "bullet 2 - land 3" is one of the KM comparisons. We can compute the CMPS score using two versions of the CMPS algorithm.

```{r, eval=FALSE}
land2_3 <- bullets$sigs[bullets$bulletland == "2-5"][[1]]
land1_2 <- bullets$sigs[bullets$bulletland == "1-4"][[1]]

# compute cmps

# algorithm with multi-peak insepction at three different segment scales
cmps_with_multi_scale <- extract_feature_cmps(land2_3$sig, land1_2$sig, 
                                              npeaks.set = c(5,3,1), include = "full_result")

# algorithm with multi-peak inspection at the basis scale only
cmps_without_multi_scale <- extract_feature_cmps(land2_3$sig, land1_2$sig, 
                                                 npeaks.set = 5, include = "full_result")
```

We can also compute the CMPS scores (using the multi segment lengths strategy) for all 36 land-by-land comparisons. 

```{r}
#      [,1] [,2] [,3] [,4] [,5] [,6]
# [1,]    2    3    2    3    1    2
# [2,]    2    1   17    1    2    3
# [3,]    1    1    3   14    2    2
# [4,]    2    1    1    1   10    1
# [5,]    2    2    1    1    1   15
# [6,]   16    3    1    2    1    1
```


**Visualize and Understand CMPS results**

We also implemented graphing tools for visualizing results of the CMPS algorithm. The goal is to provide users with tools to inspect each of the basis segments and to help them have a better understanding of how the algorithm works. Let's continue with the example above and take its results. 

```{r, eval=FALSE}
sig.plot <- cmps_signature_plot(cmps_with_multi_scale)
```

`cmps_signature_plot` takes the "full result" of `extract_feature_cmps` (setting `include = "full_result"`) and returns a list of 5 elements. 

The first element is `segment_shift_plot`. On this plot only basis segments that agree with the congruent registration position (i.e. the segments that are congruent matching profile segments) are plotted along with the comparison profile. When plotting, each of those basis segments will be shifted to the position where the basis segment obtains a cross-correlation peak and is within the tolerance zone of the congruent registration position. 

```{r, eval=FALSE}
sig.plot$segment_shift_plot
```

```{r, echo=FALSE, out.width="300px", fig.cap="The dark grey line shows the comparison profile; each red line segment shows one comgruent matching profile segment. "}
knitr::include_graphics("img/sigplot1.png", dpi = 100)
```


The second element is called `signature_shift_plot`. On this visual both the reference profile and the comparison profile are plotted. The reference profile is aligned with the comparison profile based on the congruent registration position. And the congruent matching profile segments are highlighted. 

```{r, eval=FALSE}
sig.plot$signature_shift_plot
```

```{r, echo=FALSE, out.width="300px", fig.cap="The dark grey line shows the comparison profile; the red line shows the reference profile. Solid part is the congruent matching profile segments, and the dashed part shows segments that do not agree with the congruent registration position. "}
knitr::include_graphics("img/sigplot2.png", dpi = 100)
```

Other elements of this list are `seg_shift`, `sig_shift`, and `seg.pos`. These elements are essentially used for generating visuals above but also provide insights about the best fitted position for each congruent matching profile segments and for the reference profile. `sig.plot$seg.pos` can also tell us which basis segments are the congruent matching profile segments. 

As `cmps_signature_plot` focuses on the signature level, on the other hand, `cmps_segment_plot` focuses on the segment level. It not only takes the "full result" of `extract_feature_cmps`, but also takes an argument `seg.idx`, which indicates which segment to be inspected. For example, after checking `sig.plot$seg.pos` we noticed that segment 6 is not one of the congruent matching profile segments. So we can set `seg.idx = 6` in order to have a closer look at segment 6 and why it disagrees with the congruent registration position. `cmps_signature_plot` also returns a list. Each element of this list is also a list and corresponds to one segment scale of this basis segment.

```{r, eval=FALSE}
seg.plot <- cmps_segment_plot(cmps_with_multi_scale, seg.idx = 6)
```



Take the first element of `seg.plot` as an example, it corresponds to the first segment scale (the original scale) of the 6th basis segment and carries two plots, `segment_plot` and `scale_ccf_plot`.

Remember that when computing the CMPS score, we were using `npeaks.set = c(5, 3, 1)`. This means that for the first segment scale, 5 peaks are identified in the cross-correlation curve. `segment_plot` plots the 6th basis segment in its first scale at its original position as well as the positions where the basis segment obtains its 5 cross-correlation peaks. 

```{r, eval=FALSE}
seg.plot[[1]]$segment_plot
```

```{r, echo=FALSE, out.width="300px", fig.cap="segment_plot for segment 6 at scale 1. The original position of segment 6 is indicated by the solid black line. Positions where the segment achieves the 5 highest cross-correlations are indicated by the dashed line segments. "}
knitr::include_graphics("img/segplot1.png", dpi = 100)
```

And the `scale_ccf_plot` plots the cross-correlation curve. We can see that 5 highest peaks are identified and marked on the plot. 

```{r, eval=FALSE}
seg.plot[[1]]$scale_ccf_plot
```

```{r, echo=FALSE, out.width="300px", fig.cap="scale_ccf_plot shows the cross-correlation curve between the comparison profile and segment 6 at scale 1. The five highest peaks are marked by dots. The vertical red dashed line indicates the congruent registration position; the green dashed line shows a candidate position for the consistent correlation peak; the blue dashed lines show the region of the tolerance zone. We can see here none of the five highest peaks agrees with the candidate position, so a consistent correlation peak cannot be identified and we don't take segment 6 as a congruent matching profile segment"}
knitr::include_graphics("img/segplot2.png", dpi = 100)
```

Additionally, if we put `segment_plot` and `scale_ccf_plot` for all three segment scales together, we can have more insights about why segment 6 is not a congruent matching profile segment. 

```{r, eval=FALSE}
library(ggpubr)

ggarrange(plotlist = unlist(seg.plot, recursive = FALSE),
          ncol = 2, nrow = 3)
```

```{r, echo=FALSE, out.width="400px", fig.cap="put segment_plot and scale_ccf_plot of all scales together. We are identifying five highest peaks at scale 1, three peaks at scale 2, and one peak at scale 3 since npeaks.set = c(5, 3, 1). Putting these plots together can help better understand why segment 6 is not a congruent matching profile segment. Here we can also see clearly that increasing segment length can reduce the number of false positive peaks."}
knitr::include_graphics("img/segplot3.png", dpi = 100)
```

The red vertical dashed line indicates the congruent registration position. We can see that the segment 6 does obtain a peak near to the congruent registration position at scale two and scale three, respectively; however, this position doesn't give one of the five highest peaks at scale one. As a result, segment 6 fails to identify the consistent correlation peak (ccp) and fails to become one of the congruent matching profile segments according to the multi segment lengths strategy. 



## Results

**Metrics Based on CMPS scores**

```{r, eval=FALSE, echo=FALSE}
hamby252_results <- readRDS("C:/Research/Bullet/Bullet_Rcode/hamby252_results.rds")
hamby44_results <- readRDS("C:/Research/Bullet/Bullet_Rcode/hamby44_results.rds")
```


In (NIST's original paper) that presents the CMPS algorithm researchers applied the CMPS method to one of the Hamby set scans (Hamby 252). In order to show that our implementation of the CMPS algorithm is able to reproduce the results in (original paper) and is able to be used for other data sets, we applied our implementation to both Hamby set 252 and Hamby set 44. Since the CMPS algorithm works with, in our case, bullet signatures, we conducted some data-processing. For both Hamby 252 and Hamby 44, we started with x3p files in the database, followed the framework proposed by Hare and Hofmann using the same set of parameters for both data sets, removed outliers, and obtained bullet signatures for each bullet land impression. Note that [in NIST's paper] they used a different framework to obtain bullet signatures. However, since NIST's work is not open-source, we were not able to follow their framework and were only able to reproduce the results for Hamby set 252 qualitatively.

The CMPS score can be considered as a similarity score of two profiles. Then how can we get a similarity score of two bullets based on CMPS scores? In (the original paper) researchers introduced two similarity metrics, $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$, for bullet comparisons based on CMPS scores of bullet signature comparisons. For example, there are in total 6 $\times$ 6 LEA profile comparisons in order to compare two bullets in Hamby study since each bullet has 6 LEA profiles. And a CMPS score will be found for every profile comparison. $\mathrm{CMPS_{max}}$ is the highest CMPS score among all profile comparisons. And $\mathrm{\overline{CMPS}_{max}}$ is the highest possible average CMPS score of profile comparisons that are in the same phase.

Here are the CMPS scores of all 36 profile comparisons of the bullets in the example above.

```{r}
#      [,1] [,2] [,3] [,4] [,5] [,6]
# [1,]    2    3    2    3    1    2
# [2,]    2    1   17    1    2    3
# [3,]    1    1    3   14    2    2
# [4,]    2    1    1    1   10    1
# [5,]    2    2    1    1    1   15
# [6,]   16    3    1    2    1    1
```

In this example, the $\mathrm{CMPS_{max}}=17$ and $\mathrm{\overline{CMPS}_{max}}=(16+3+17+14+10+15)/6=12.5$. 

**Hamby 252**

Figure 2 shows the distribution of $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$ after we applied the CMPS algorithm to Hamby set 252. Although the CMPS scores we found here are not exactly the same as those presented in the [original paper] since we don't have the exact parameters and functions used by the researchers, the results we obtained are promising. For both $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$ we can observe a clear separation between the known matching comparisons (KM) and known non-matching comparisons (KNM). Table x shows some summary statistics. 

The parameters we used in `extract_feature_cmps` are:

```{r, eval=FALSE}
extract_feature_cmps(
  x, y,
  seg_length = 50,
  Tx = 25,
  npeaks.set = c(5,3,1),
  include = "nseg"
)
```

Note that for Hamby set 44, one unit represents 1.5625 \textmu m so setting `seg_length = 50` makes each basis segment have length 78.125 \textmu m. And `Tx = 25` makes the tolerance zone be $\pm 39.0625$ \textmu m. This is to mimic the parameters used in the [original paper].

<!-- this is figure 2 -->
```{r, echo=FALSE, out.width="400px"}
# [4] "span1=0.25, span2=0.03, rm_outliers = TRUE, 5025, 531"  
knitr::include_graphics("img/hamby252_v1.png", dpi = 100)
```

table 1:

<!-- |Parameters             | $\mathrm{CMPS_{max}}$ - KNM's max| $\mathrm{CMPS_{max}}$ - KM's min| $\mathrm{\overline{CMPS}_{max}}$ - KNM's max| $\mathrm{\overline{CMPS}_{max}}$ - KM's min| -->
<!-- |:----------------------|---------------------------------:|--------------------------------:|--------------------------------------------:|-------------------------------------------:| -->
<!-- |span1=0.25, (5, 3, 1)  |                                 7|                               10|                                       3.6000|                                      6.6667| -->
<!-- |span1=0.25, (10, 6, 1) |                                 9|                               13|                                       4.8333|                                      9.1667| -->
<!-- |span1=0.75, (5, 3, 1)  |                                 6|                               11|                                       3.1667|                                      6.6000| -->

```{r, echo=FALSE}
# library(knitr)
# library(kableExtra)
# rtt <- readRDS("summary_table.rds")
# colnames(rtt) <- 
rtt <- data.frame(parameters = c("span1=0.25, (5, 3, 1)", "span1=0.25, (10, 6, 1)", "span1=0.75, (5, 3, 1)"),
                  p1 = c(7,9,6),
                  p2 = c(10, 13, 11),
                  p3 = c(3.6, 4.833, 3.167),
                  p4 = c(6.667, 9.167, 6.6))


knitr::kable(rtt, 
             row.names = FALSE, digits = 4,
             col.names = c("Parameters",
                           "$\\mathrm{CMPS_{max}}$ - KNM's max",
                           "$\\mathrm{CMPS_{max}}$ - KM's min",
                           "$\\mathrm{\\overline{CMPS}_{max}}$ - KNM's max",
                           "$\\mathrm{\\overline{CMPS}_{max}}$ - KM's min")) 
```


Figure 3 shows the results for Hamby set 44. Again, we are able to see a clear separation between the KM comparisons and the KNM comparisons, but it would be better if the separation can be further enlarged. Table 1 shows some summary statistics for Hamby set 44. 

For Hamby set 44, the parameters we used in `extract_feature_cmps` are:

```{r, eval=FALSE}
extract_feature_cmps(
  x, y,
  seg_length = 61, 
  Tx = 30,
  npeaks.set = c(5,3,1),
  include = "nseg"
)
```

Note that we used different values here for `seg_length` and `Tx` because our Hamby set 44 scans have a different scanning resolution. One unit here represents 1.29 \textmu m. So here each basis segment has length 78.69 \textmu m, and the tolerance zone is $\pm 38.7$ \textmu m.

<!-- this is figure 3 -->

```{r, echo=FALSE, out.width="400px"}
# [1] "span1=0.25, span2=0.03, rm_outliers"
knitr::include_graphics("img/hamby44_v1.png", dpi = 100)
```

Figure 4 shows another Hamby set 44 results, but the parameter `npeaks.set` is now `c(10, 6, 1)`. We can see that the separation between KM comparisons and KNM comparisons is increased. This shows that the parameters used in the CMPS algorithm can affect the CMPS results, and an open-source implementation of the algorithm will facilitate efforts of cross-validating these parameters.

<!-- this is figure 4 -->

```{r, echo=FALSE, out.width="400px"}
# [5] "span1=0.25, span2=0.03, rm_outliers, c(10,6,1)"
knitr::include_graphics("img/hamby44_c1_v1.png", dpi = 100)
```

For the results above we used `span1=0.25` in the function `cc_get_signature` when computing the signatures/profiles; however, in this example we used `span1=0.75` and changed the characteristic of those profiles. As we can see in figure 5, this change also affects the CMPS results.

<!-- this is figure 5 -->

```{r, echo=FALSE, out.width="400px"}
# [4] "span1=0.75, span2=0.03, rm_outliers"  
knitr::include_graphics("img/hamby44_c2_v1.png", dpi = 100)
```

[The codes generating those results can be found in the appendix. ???]


## Conclusion

We presented the CMPS package, an open-source implementation of the congruent matching profile segments (CMPS) algorithm. The CMPS algorithm was proposed by NIST in 2019 and was made for objective tool marks comparisons. In this paper, functions included in the package were illustrated along with the basic logic of the CMPS algorithm. 
And we used a small dataset included in the package as an example to explain the usage of the package. Some graphing tools were also implemented in the package so that users can visualize results and have a better understanding of both the algorithm and the results. We also applied the algorithm to two datasets in Hamby study (Hamby set 252 and Hamby set 44), and the results we obtained were promising. 

From the results of both Hamby set 252 and 44, we can see that the CMPS scores of KM comparisons computed by `extract_feature_cmps` were able to be separated from those of KNM comparisons. And at the same time, we can see that CMPS algorithm is sensitive to the choice of parameters such as segment length, number of peaks detected at each segment scale, and congruency tolerance. Some parameter choices are better in the sense that they can enlarge the separation between the KM comparisons and the KNM comparisons. And the best set of parameters depend on the dataset being used, and the choice of parameters has not been, but should be, cross-validated. 

Our open-source implementation introduces the CMPS algorithm to R community and allows everyone to use it for their own projects. It would also facilitate future studies on parameter cross-validation and the development of statistical methods to modeling KM and KNM CMPS score distributions.  



### About this format and the R Journal requirements

`rticles::rjournal_article` will help you build the correct files requirements: 

* A R file will be generated automatically using `knitr::purl` - see
https://bookdown.org/yihui/rmarkdown-cookbook/purl.html for more information.
* A tex file will be generated from this Rmd file and correctly included in
`RJwapper.tex` as expected to build `RJwrapper.pdf`.
* All figure files will be kept in the default rmarkdown `*_files` folder. This
happens because `keep_tex = TRUE` by default in `rticles::rjournal_article`
* Only the bib filename is to modifed. An example bib file is included in the
template (`RJreferences.bib`) and you will have to name your bib file as the
tex, R, and pdf files.
