---
title: An Open-Source Implementation of the CMPS Algorithm for Assessing  Similarity of Bullet Signatures
header-includes:
  - \usepackage{xcolor}
  - \usepackage{longtable}
  - \usepackage{adjustbox}            
  - \usepackage[font=small,skip=5pt]{caption}
  - \usepackage{subcaption}
  - \usepackage{afterpage}
author:
  # see ?rjournal_article for more information
  - name: Will W. Ju
    affiliation: Department of Statistics
    address:
    - Center for Statistics and Applications in Forensic Evidence
    - Iowa State University
    - 2438 Osborn Dr
    - Ames, IA 50011
    url: https://github.com/willju-wangqian
    orcid: 0000-0002-9079-593X
    email:  wju@iastate.edu
  - name: Heike Hofmann
    url: https://github.com/heike
    email: hofmann@iastate.edu
    orcid: 0000-0002-9079-593X
    affiliation: Department of Statistics
    address:
    - Center for Statistics and Applications in Forensic Evidence
    - Iowa State University
    - 2438 Osborn Dr
    - Ames, IA 50011
abstract: >
  An abstract of less than 150 words.
preamble: |
  % Any extra LaTeX you need in the preamble
  
# per R journal requirement, the bib filename should be the same as the output 
# tex file. Don't forget to rename the bib file and change this example value.
bibliography: CMPSpaper-writing.bib

output: rticles::rjournal_article
---


```{=tex}
\newcommand{\hh}[1]{{\textcolor{orange}{#1}}}
\newcommand{\wj}[1]{{\textcolor{blue}{#1}}}
\setlength{\parindent}{0pt}
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(tidyverse)
library(bulletxtrctr)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  out.width = "\\textwidth",
  fig.align = "center",
#  cache=TRUE,
  dpi = 100
)
```


```{r setup_knitr, echo=FALSE}
## From Josh O'Brien's stackoverflow answer:
## http://stackoverflow.com/questions/11030898/knitr-how-to-align-code-and-plot-side-by-side
## These two settings control text width in codefig vs. usual code blocks
partWidth <- 35
fullWidth <- 60
options(width = fullWidth)

##  (1) CHUNK HOOK FUNCTION
##   First, to set R's textual output width on a per-chunk basis, we
## need to define a hook function which temporarily resets global R's
## option() settings, just for the current chunk
knit_hooks$set(r.opts = local({
    ropts <- NA
    function(before, options, envir) {
        if (before) {
            ropts <<- options(options$r.opts)
        } else {
            options(ropts)
        }
    }
}))

## (2) OUTPUT HOOK FUNCTION

##   Define a custom output hook function. This function processes _all_
## evaluated chunks, but will return the same output as the usual one,
## UNLESS a 'codefig' argument appeared in the chunk's header.  In that
## case, wrap the usual textual output in LaTeX code placing it in a
## narrower adjustbox environment and setting the graphics that it
## produced in another box beside it.

defaultChunkHook <- environment(knit_hooks[["get"]])$defaults$chunk

codefigChunkHook <- function(x, options) {
  main <-  defaultChunkHook(x, options)
  before <-
    "\\vspace{1em}
\\begin{adjustbox}{valign=t}
\\begin{minipage}{.39\\textwidth}\n"
  after <-
    paste("\\vspace{1em}
\\end{minipage}
\\begin{minipage}{.59\\textwidth}",
    paste0("\\includegraphics[width=\\textwidth]{CMPSpaper_writing_files/figure-latex/",
                 options[["label"]], "-1.pdf}
\\end{minipage}
\\end{adjustbox}"),
          sep = "\n")
  ## Was a codefig option supplied in chunk header?
  ## If so, wrap code block and graphical output with needed LaTeX code.
  if (!is.null(options$codefig)) {
    main <- gsub("```","", main)
    main <- gsub("=latex","", main)
    main <- paste0("{\\small ", main, "}")
    return(sprintf("%s\n%s\n%s", before, main, after))
  } else {
    return(main)
  }
}

knit_hooks[["set"]](chunk = codefigChunkHook)


## (3) TEMPLATE
##   codefig=TRUE is just one of several options needed for the
## side-by-side code block and a figure to come out right. Rather
## than typing out each of them in every single chunk header, we
## define a _template_ which bundles them all together. Then we can
## set all of those options simply by typing opts.label="codefig".

opts_template[["set"]](
codefig = list(codefig = TRUE, fig.show = "hide",
               r.opts = list(width = partWidth),
               tidy.opts = list(width.cutoff = partWidth)))
```




## Introduction


In this paper we present an open-source implementation of the algorithm of the Congruent Matching Profile Segments (CMPS) method. @cmps developed the CMPS method for "objective comparison of striated tool marks" and demonstrated its use in some examples of comparing bullet signature correlations. Although @cmps conceptually described the CMPS algorithm  in their paper, \hh{the authors did not release an implementation of their method}. Thus, our effort here is to introduce the CMPS method to the `R` [@R] community and provide an open-source, publicly available implementation of the algorithm  to use, review, and  improve. Our implementation is made available as part of the  `R` package  `CMPS` on GitHub at \url{https://github.com/willju-wangqian/CMPS}. 

 Firearm examination has  played an important role in  convictions in the United States criminal justice system. \hh{Do we have a number or a percentage of cases where firearm examination has played a role? or maybe gun violence? XXX}
 
An important task of firearm examination is \hh{to answer the question of whether two pieces of evidence come from the same source or whether a piece of evidence matches a sample obtained from a specific firearm. Here, in particular, we are interested } to determine whether two bullets were fired from the same gun barrel. 
\hh{Assessing the similarity between two bullets is based on a comparison of  striation marks acquired during the firing process as bullets are propelled through the barrel. }
\hh{Current state of art sees firearms examiners make an assessment of similarity based on a visual comparison, generally, using a comparison microscope. This practice has been criticized for its lack of objectivity and the associated problem in calculating an error rate [@pcast].}
<!--It is achievable because lands in a gun barrel create striation marks on the bullet during the firing process, and it is believed that the same gun barrel will create highly similar striation marks on the bullets it fired. Typically the striation marks are created by lands in a barrel, so the striation marks are also sometimes refered as land engravings, and the areas the marks occupy are called land engraved areas (LEA). However, in recent years people became more cautious about firearms identification, and criticism of its subjective methodology arose.--> A report published by @nrc states that "[m]uch forensic evidence-including, for example, bite marks and firearm and toolmark identification—is introduced in criminal trials without any meaningful scientific validation, determination of error rates, or reliability testing to explain the limits of the discipline." To overcome those criticisms and concerns, researchers have been making an effort to build databases [@nistdb] and develop frameworks and algorithms that bring an objective and quantitative assessment into the field \hh{XXX cite some of these efforts - make sure to say that it is not an exhaustive list}. \hh{XXX The bullet signatures weren't mentioned before - make sure to include that there is a whole section that discusses how bullet signatures are extracted from scans.}
\wj{The notion of bullet signatures is one of the results of these efforts. Bullet signatures can be extracted from bullet land engraved areas (LEAs), typically one for each land engraved area, and how those bullet signatures are extracted from scans will be discussed in the Background section. Since bullet signatures can numerically describe the striation marks on the bullet and can be understood by algorithms, they played an important role in bringing objectivity into the field. }
In the following sections we will: review the background of bullet signature comparisons, discuss how we followed the idea described by @cmps for the implementation of the CMPS algorithm, and present results of applying our implementation to real data. 

## Background 


### Hamby Data Set

The datasets we worked with come from the James Hamby Consecutively Rifled Ruger Barrel Study [@brundage; @hamby; @Hamby:2019],  in particular, Hamby set 252 and Hamby set 44. 
For each Hamby set, a total of 35 bullets is fired from ten \hh{consecutively manufactured} Ruger P-85 pistol barrels. \hh{Two bullets are fired from each barrel, making up a set of 20 reference bullets. An additional 15 bullets are fired from these ten barrels in a fashion unknown to the study participant. The aim of the Hamby Study was to have firearms examiners identify which barrel each of the 15 questioned bullets was fired from. The Ruger P-85 barrels are traditionally rifled barrels with six grooves and lands \hh{as shown in \autoref{fig:bullet}}. During the firing process, grooves and lands are engraved on a bullet. Firearms examiners use striation marks on land engraved areas (LEAs) for their visual comparison. For algorithmic purposes, }
3D topographical images \hh{land engraved areas} were obtained and stored in  x3p format (XML 3-D Surface Profile). The x3p format provides a standard way of exchanging 2D and 3D profile data. It conforms to the ISO5436-2 standard [http://sourceforge.net/p/open-gps/mwiki/X3p/]  adopted by the OpenFMC (Open Forensic Metrology Consortium), a group of firearm forensics researchers who contributes to the establishment of best practices of using metrology in forensic science. Hamby set 252 were scanned using a NanoFocus lens at 20x magnification with the scan resolution being 1.5625 \textmu m $\times$ 1.5625 \textmu m per pixel. Hamby set 44 was scanned \hh{at the Roy J Carver High-Resolution microscopy lab at Iowa State. These scans were acquired with a Sensofar Confocal Light Microscope at 20x magnification for a nominal resolution of 0.645 \textmu m $\times$ 0.645 \textmu per pixel}.  Both Hamby set 252 and Hamby set 44 are publicly available on the NIST Ballistics Database Project [@nistdb].


### Extracting signatures from LEA scans

The automated framework  used in this paper was proposed by @aoas. In order to obtain bullet signatures from the x3p files of bullet land engravings, we use the `R` packages `x3ptools` [@x3ptools] and `bulletxtrctr` [@bulletxtrctr]. `x3ptools` \hh{is a package to read, write, and generally, process } x3p files. \hh{The `bulletxtrctr` package implements a pipeline for extracting and comparing signatures from scans of land-engraved areas.}
<!--In the case of Hamby set 252, we need to convert the measurements of x3p files from meters to microns (`x3ptools::x3p_m_to_mum`) and rotate x3p files to make the long axis horizontal (`x3ptools::x3p_rotate`).--> 
  <!--\hh{it's land **engraved** areas, not impressions (that was wrong in Eric's first paper). Impressions are marks from impacts, such as the hit of a hammer or the hit from the breech face. Engravings are scratch marks.}-->
  \hh{\autoref{fig:process} gives an overview of all of the steps in the process from scan to signatures.}
\autoref{fig:process}(a) shows a \hh{rendering of a 3d scan of a } bullet land  engraved area. The raised portion of the surface \hh{on the left and right of the scan are parts of the adjacent groove engraved areas (GEAs)}, \hh{the middle area shows a land-engraved area (LEA) with well expressed} striation marks. The first step of obtaining the bullet signature is to extract a cross-section at a fixed height along the land engraving.
<!--\hh{The next section is at an awkward level of detail - there's lots of details, but without the parameter settings it is still not a reproducible description. Could you instead describe things conceptually, and then link to the code that does this particular image?} -->
The white horizontal line in \autoref{fig:process}(a) indicates which cross-section was identified by the algorithm to represent the LEA; \autoref{fig:process}(b) shows the corresponding cross-sectional view. <!--Then we can acquire the crosscut data (`ccdata`) of the scan at this height. --> \hh{XXX passive voice for things that are not part of this paper :)}
Groove engraved areas are removed from the analysis as indicated by the vertical blue lines in \autoref{fig:process}(c) and \autoref{fig:process}(d)). A non-parametric LOESS smooth  [@loess] is fitted to capture the bullet curvature (\autoref{fig:process}(e)) and, finally, the **bullet signature** (\autoref{fig:process}(f)) is obtained as residuals of the cross-section and the fitted smooth. 
Note, that in @cmps bullet signatures are  referred to as bullet profiles. However, to avoid confusion, we distinguish the notion of bullet signatures from bullet profiles. \wj{Bullet profiles are \hh{shown in panels (b), (c), and (d) of \autoref{fig:process}}, while \autoref{fig:process}(f) shows the corresponding bullet signature.} 
\hh{Identifiying the groove engraved areas correctly is fundamental for a correct down-stream analysis of the signatures. To allow for a human-in-the middle inspection and intervention we have provided an interactive web-application, implemented as `R` Shiny App [@shiny],}   `bulletinspectR` to identify and correct those errors. 
\hh{An example of the extraction process with corresponding code and parameter settings can be found at XXX.}
Note that \hh{the process of extracting signatures might be different from the one used in @cmps because no code or parameter settings are made available publicly.}

<!-- `bulletxtrctr::x3p_crosscut_optimize` can be used to determine an ideal \hh{XXX ideal is a dangerous word} height, and `bulletxtrctr::x3p_crosscut` can be used to acquire the crosscut data (`ccdata`). \autoref{fig:process}(c) shows the typical pattern of the crosscut data, where "wedges" can be found on the left and right side and indicate the boundary between the land engraving and the groove engraving. `bulletxtrctr::cc_locate_grooves` is used to locate and chop these wedge areas so that only the curve of the land engraving in the middle is kept. With the groove engravings excluded, we then use `bulletxtrctr::cc_get_signature` to smooth out the land engraving curvature using LOESS (locally estimated scatter plot smoothing) [@loess] and obtain the bullet signature. \autoref{fig:process} illustrates this framework. Sometimes the algorithm in our framework cannot determine the ideal location of the crosscut or the grooves due to the deformation of a bullet, so we also developed a `R` Shiny App called `bulletinspectR` to identify and correct those errors. Note that NIST researchers used a different way of getting the bullet signatures in their paper [@cmps]. -->

```{r bullet, echo=FALSE, out.width=".8\\textwidth", fig.cap="Photo of a traditionally rifled gun barrel (left) and a fired bullet (right)."}
knitr::include_graphics("img/barrel_bullet_ps.png", dpi = 100)
```


```{r process, echo=FALSE, out.width=".9\\textwidth", fig.cap="A framework of obtaining a bullet signature. (a) front view of a scanned land engraved area (LEA). The selected crosscut location is indicated by the white line. (b) view of the cross-section of the land engraved area at the white line in (a). (c) the crosscut data plotted in 2D; blue vertical lines indicate the position of left and right grooves. (d) the crosscut data after chopping the left and right grooves. (e) the fitted curvature using LOESS. (f) after removing the curvature from the crosscut data, the bullet signature is obtained"}
knitr::include_graphics("img/figure1_v2.PNG", dpi = 100)
```




### Conceptual idea of CMPS
\hh{Most algorithms for comparing striation marks are based on the digitized signatures XXX} and produce a similarity score [@song2005, @ChumbleyL_Scott2010VoTM, @aoas, @pmid30444940 ].
 The congruent matching profile segments (CMPS) algorithm, developed by @cmps for "objective comparison of striated tool marks", is one such algorithm. The algorithm's main idea  is to take a set of consecutive and non-overlapping basis segments from  the reference   and  for each segment find the "best" registration position on the comparison  (the other bullet signature) with respect to their cross-correlation values. \hh{From a comparison of these registration positions, a } **congruent registration position** is identified, and the number of basis segments taking the congruent registration position is the CMPS score. 
  \hh{High CMPS scores are achieved between more similar signatures and are therefore indicative of a same-source pair. Low scores between pairs of signatures are attributed to different source pairs.} 
  \hh{XXX What threshold did @cmps identify as the boundary between different source and same source? And what was the error rate in their example?}
  \wj{they didn't talk about a specific threshold or error rates} \hh{XXX Is there a way to infer the error based on the example? ... 'while the authors did not mention a specific threshold of the CMPS to distinguish between same-source and different-source comparison, a CMPS value of Y results in an error rate of Z in the example.'}
 The CMPS algorithm can assist firearm examiners with drawing a conclusion \hh{about the source of a comparison pair}. \hh{Unfortunately, @cmps did not release any code or specific parameter settings for their implementation of the } CMPS algorithm. 
Thus, in this paper we present an open-source implementation of the CMPS algorithm \hh{in the R package CMPS available from XXX github / CRAN}. 
With our implementation, one can compute the CMPS score of a comparison using the following code:

\hh{XXX could you make this example functional?}
```{r, eval=FALSE}
# install.packages("devtools") 
# devtools::install_github("willju-wangqian/CMPS")

library(CMPS)
data(bullets)

sig1 <- bullets$sigs[[2]]$sig
sig2 <- bullets$sigs[[9]]$sig
sig3 <- bullets$sigs[[10]]$sig

cmps.result.KM <- extract_feature_cmps(sig1, sig2)
cmps.result.KNM <- extract_feature_cmps(sig1, sig3)
```

\wj{In this example, the comparison between `sig1` and `sig2`, two signatures coming from the same source (a known-match comparison), gets a CMPS score of 17; the comparison between `sig1` and `sig3`, two signatures coming from different sources (a known non-match comparison), gets a CMPS score of 2.}


<!-- In the example in section "Implementation" we see that two bullet signatures coming from the same source get a CMPS score of X, while two signatures coming from different sources get a CMPS score of Y.  -->

We also implemented graphing tools for users to better understand these results as well as the algorithm itself.

The section "Implementation" will go through the algorithm and show how to use the "CMPS" package. An further example that illustrates the main points are also included. The section "Results" presents the results of evaluating the CMPS package using Hamby set 252 and Hamby set 44. And the last section covers some final discussion and conclusions.


## Implementation

**Algorithm.** 

Conceptually, the CMPS algorithm consists of three main steps:

1. **cut the reference signature into consecutive, non-overlapping and equal-length basis segments:**
The command `get_segs(x, len=50)` implements this step:  it takes  bullet signature `x` in the format of a numeric vector and cuts it into consecutive, non-overlapping and equal-length segments of length `len`.

2. **register each basis segment on the comparison signature:** 
Calculate the cross-correlation curve between a basis segment `x` and the comparison signature `y` using the function `get_ccf4(x, y, ...)`. \hh{XXX position is really the lag - i.e. we can compare lags across  different segments.}
A position is considered "good" if it results in a peak in the cross-correlation between the basis segment and the comparison.
<!-- the cross-correlation between the basis segment and the comparison is above a pre-defined threshold.  -->
The best registration position is decided upon using a multi-peak inspection with or without different segment lengths:

    2.1. **multi-peak inspection (without different segment lengths):** each basis segment identifies positions of the top 5 highest peaks (if `npeaks.set = 5`) in the cross-correlation curve. Small segment lengths might indicate false positive peaks. Therefore all 5 peaks are considered as candidates for the "best" registration position.

    2.2. **multi-peak inspection with different segment lengths:** for this version of the CMPS algorithm, each basis segment finds only one "best" registration position. This "best" registration position can be found by conducting multi-peak inspection multiple rounds. The first round is executed as stated in step 2.1. After that first round, the segment length is increased, a new cross-correlation curve is computed, and another set of  peaks in the cross-correlation curve is identified together with the candidate positions. Typically, fewer number of peaks are identified in this round (because the increased segment length reduces the chance of false positive peaks). This process can be repeated multiple times. In the last round, only one highest peak should \hh{XXX should? this is ambiguous. What happens if no peak or multiple peaks are found?} be identified. If the same or 'similar enough' (see step 3) position can be identified for all different segment length, this position will be selected as the "best" registration position and is called the "consistent correlation peak" (ccp). \wj{In order to use this version of the CMPS algorithm, we set `npeaks.set` as a numeric vector of multiple values. For example, if we set `npeaks.set = c(5, 3, 1)`, 5 peaks will be identified in the first round, 3 peaks in the second round, and 1 peak in the final round.} 
    
3. **determine the congruent registration position**:
candidate positions across different segments \hh{XXX how is this done in situation 2.1? } are compared using a small tolerance \wj{parameter `Tx`} and basis segments with a congruent registration position are determined. These segments are called the "congruent matching profile segments" (CMPS), and the number of CMPS is the CMPS score of the comparison.


<!-- we conduct the "multi-peak inspection at different segment lengths". After having the multi-peak inspection for a basis segment of its original length, we then double the segment length by including profiles of half the current length -->


<!-- If the reference profile and the comparison profile matches perfectly, every basis segment should vote for exactly the same registration position.  -->

<!-- compute the cross-correlation function between each basis segment and the comparison profile; -->

\hh{In the CMPS package, these three steps are implemented using a set of key functions:}



<!-- step 3) if the multi segment lengths strategy is being used, each basis segment would increase its length and compute a new cross-correlation function with the comparison profile in order to identify a potential “consistent correlation peak”; if the multi segment lengths strategy is not being used, each segment would then find 5 peaks in its cross-correlation function; -->

* `get_seg_scale` takes a basis segment and increases its segment length. `scale=1` gives the original length of the basis segment. Increasing `scale` by 1 will double the segment length.

* `get_ccr_peaks` takes a segment and the comparison signature, then computes the correlation coefficient curve between them and finds peaks on the correlation coefficient curve. The number of peaks detected is equal to `npeaks`. And we are using `rollapply` to find peaks on the curve effectively.

* `get_ccp` checks if the "consistent correlation peak" exists under the framework of multi segment lengths strategy. Since we are requiring the highest segment scale identifies only one peak, we just need to check if this peak shows any "consistency". In other words, we check if this peak is also identified as a peak in other segment scales. 


* `get_CMPS` considers all basis segments and their identified peak positions to determine the congruent registration position. The goal is to find a peak position that is agreed by the most basis segments. Since small errors are allowed, a tolerance zone would serve as a selection window. `get_CMPS` will move this selection window from left to right and go through all possible positions and check the number of basis segment that identifies a peak in the selection window for each position. Since we are moving this tolerance zone from left to right one unit a time, some consecutive positions are expected to have the same number of basis segments. [?.?] In that case the median of all tied and consecutive positions will be chosen as the congruent registration position. As long as the congruent registration position is determined, the number of basis segments that identify a peak in this position is the CMPS score.

Note that there are parameters in this algorithm that can be specified by the users to conform the structure of their data, such as the length of basis segments in step 1, the number of peaks identified in step 3, and the length of the tolerance zone in step 3. In our implementation of the CMPS algorithm we took the original CMPS paper [@cmps] as the reference to determine the default values of these parameters. 
The main function that follows the CMPS algorithm is called `extract_feature_cmps`. It consists of all steps of the algorithm and receives parameters from the users. 

* `seg_length` specifies the length of basis segments [(in mm?)] mentioned in step 1; 
* `npeaks.set` determines the number of peaks and whether the function uses the multi segment lengths strategy. If `npeaks.set` is a numeric vector of length 1, for example `npeaks.set = c(5)`, then the function will not use multi segment lengths and find 5 peaks in the correlation coefficient curve for each basis segment; on the other hand, if the vector length of `npeaks.set` is larger than 1, for example `npeaks.set = c(5, 3, 1)`, the function will take advantage of the multi segment lengths strategy, finding 5 peaks in the original scale, 3 peaks in the second scale and 1 peak in the third scale. Note that if the multi segment lengths strategy is being used, the last element of `npeaks.set` should always be 1. 
* `Tx` gives the size of tolerance zone mentioned in step 4;
* `include` determines what information should be included in the function output. By default, `include = NULL` and the function output will only contain the `CMPS.score`. However, besides the most important `CMPS.score`, there are other pieces of information related to the CMPS score that one might be interested in, such as 
  - `nseg`: the number of basis segments we get from the reference signature; this is also the highest possible CMPS score of the comparison;
  - `congruent.pos`: the congruent registration position;
  - `congruent.seg.idx`: the indices of all basis segments that agree with the congruent registration position;
  - `segments`: the list of basis segments used for the computation of CMPS score;
  - `parameters`: all inputs of `extract_feature_cmps`
For all possible options of `include`, please check the documentation of `extract_feature_cmps` or using `?extract_feature_cmps`. If we want everything to be included in the output, we can use `include = full_result`. These additional pieces of information are helpful in terms of understanding how we obtained such CMPS score. 
  

<!-- [examples https://journal.r-project.org/archive/2019/RJ-2019-044/RJ-2019-044.pdf] -->
<!-- [https://journal.r-project.org/archive/2019/RJ-2019-002/RJ-2019-002.pdf] -->


**Install**

The CMPS package is/not published on CRAN, and can be install and called by 

```{r, eval=FALSE}
install.packages(CMPS)
```

The development version can be installed by using 

```{r, eval=FALSE}
# install.packages("devtools") 
devtools::install_github("willju-wangqian/CMPS")
```

**Examples**

The `CMPS` package contains a simple example to illustrate the basic usage of the package. The data in this example are twelve bullet signatures obtained from two bullets in Hamby set 252 (Each bullet has six lands). The procedure for generating signatures from 3D bullet lands in x3p format is (algorithmic) [and has been discussed above]. And these two bullets are known to come from the same gun barrel, so for the 36 land-by-land comparisons, 6 of them are KM (known matching) comparisons and 30 are KNM (known non-matching) comparisons. To access the example data, one can use

```{r, eval=TRUE}
library(CMPS)
data(bullets)
```

And anyone who is interested in the data source can find it in `bullets$source`. One can use these links to download the original x3p files from NIST Ballistics Toolmark Research Database [@nistdb]. `bulletxtrctr::read_bullet(urllist = bullets$source)`

**extract_feature_cmps**

`extract_feature_cmps` integrates all steps of the CMPS algorithm. It takes two bullet signatures and computes the CMPS score. 

```{r, eval=FALSE}
extract_feature_cmps(
  x,
  y,
  seg_length = 50,
  Tx = 25,
  npeaks.set = c(5, 3, 1),
  include = NULL
)
```

The comparison between "bullet 1 - land 2" and "bullet 2 - land 3" is one of the KM comparisons. We can compute the CMPS score using two versions of the CMPS algorithm.

```{r, eval=TRUE}
sigs1 <- bullets$sigs[bullets$bulletland == "2-5"][[1]]
sigs2 <- bullets$sigs[bullets$bulletland == "1-4"][[1]]

# compute cmps

# algorithm with multi-peak insepction at three different segment scales
cmps_with_multi_scale <- 
  extract_feature_cmps(sigs1$sig, sigs2$sig, 
                       npeaks.set = c(5,3,1), include = "full_result")

# algorithm with multi-peak inspection at the basis scale only
cmps_without_multi_scale <- 
  extract_feature_cmps(sigs1$sig, sigs2$sig, 
                       npeaks.set = 5, include = "full_result")
```

We can also compute the CMPS scores (using the multi segment lengths strategy) for all 36 land-by-land comparisons. 

```{r eval=TRUE, echo=FALSE}

lands <- unique(bullets$bulletland)

comparisons <- data.frame(expand.grid(land1 = lands[1:6], land2 = lands[7:12]), 
                          stringsAsFactors = FALSE)

comparisons <- comparisons %>% mutate(
  aligned = purrr::map2(.x = land1, .y = land2, 
                        .f = function(xx, yy) {
                          land1 <- bullets$sigs[bullets$bulletland == xx][[1]]
                          land2 <- bullets$sigs[bullets$bulletland == yy][[1]]
                          land1$bullet <- "first-land"
                          land2$bullet <- "second-land"
                          
                          sig_align(land1$sig, land2$sig)
                        }))

comparisons <- comparisons %>% 
  mutate(cmps = aligned %>% purrr::map(.f = function(a) {
    extract_feature_cmps(a$lands$sig1, a$lands$sig2, include = "full")
  }))


comparisons <- comparisons %>% 
  mutate(
    cmps_score = sapply(comparisons$cmps, function(x) x$CMPS.score),
    cmps_nseg = sapply(comparisons$cmps, function(x) x$nseg)
  )

# dframe <- comparisons %>% select(land1, land2, cmps_score)
# 
# dframe %>% 
#   ggplot(aes(x = land1, y = land2, fill = cmps_score)) +
#   geom_tile() +
#   scale_fill_gradientn(
#     colors=c("darkgrey","darkorange")
#   ) +
#   geom_text(aes(label=cmps_score)) +
#   theme_bw() + 
#   coord_flip() 


comparisons <- comparisons %>%
  mutate(
    bulletA = gsub("(\\d)-\\d", "\\1", land1),
    landA = gsub("\\d-(\\d)", "\\1", land1),
    bulletB = gsub("(\\d)-\\d", "\\1", land2),
    landB = gsub("\\d-(\\d)", "\\1", land2)
  )

# comparisons %>%   
#   group_by(bulletA, bulletB) %>% tidyr::nest() %>%
#   mutate(
#     cmps_max_bar = data %>% purrr::map_dbl(
#       .f = function(d) max(compute_average_scores(land1 = d$landA,
#                                                   land2 = d$landB,
#                                                   d$cmps_score)))
#   )

dframe <- comparisons %>% select(-aligned, -cmps)

dframe$samesource <- with(dframe, bullet_to_land_predict(land1=landA, land2=landB, cmps_score, difference=1))

```

```{r tiles, echo=FALSE, fig.cap="Overview of all 36 CMPS scores resulting from a bullet-to-bullet comparison of all pairwise comparisons of the six lands on each bullet.", out.width=".7\\textwidth", fig.align="center"}
dframe <- dframe %>% mutate(
  landA = paste0("L", landA),
  landB = paste0("L", landB),
  landB = factor(landB, levels = paste0("L", c(2:6,1))),
  bulletA = paste0("Bullet ", bulletA),
  bulletB = paste0("Bullet ", bulletB)
)

dframe %>% ggplot(aes(x = landA, y = landB, fill = cmps_score)) + 
  geom_tile() + 
  geom_tile(aes(colour="same barrel"), fill=NA, data = dframe %>% filter(samesource), size=1) + 
  scale_fill_gradient2("CMPS score", low = "gray80", high = "darkorange", midpoint = 6) + 
  scale_colour_manual("Source", values="darkorange") +
  facet_grid(bulletB ~ bulletA) + xlab("Land A") + 
  ylab("Land B") + theme(aspect.ratio = 1) +
  geom_text(aes(label=cmps_score)) +
  theme_bw() +
  theme(aspect.ratio = 1)
```



<!-- ```{r} -->
<!-- #      [,1] [,2] [,3] [,4] [,5] [,6] -->
<!-- # [1,]    2    3    2    3    1    2 -->
<!-- # [2,]    2    1   17    1    2    3 -->
<!-- # [3,]    1    1    3   14    2    2 -->
<!-- # [4,]    2    1    1    1   10    1 -->
<!-- # [5,]    2    2    1    1    1   15 -->
<!-- # [6,]   16    3    1    2    1    1 -->
<!-- ``` -->


**Visualize and Understand CMPS results**

We also implemented graphing tools for visualizing results of the CMPS algorithm. The goal is to provide users with tools to inspect each of the basis segments and to help them have a better understanding of how the algorithm works. \autoref{fig:sigplot} continues with the example above and take its results. 

`cmps_signature_plot` takes the "full result" of `extract_feature_cmps` (setting `include = "full_result"`) and returns a list of 5 elements. 

The first element is `segment_shift_plot`. On this plot only basis segments that agree with the congruent registration position (i.e. the segments that are congruent matching profile segments) are plotted along with the comparison signature. When plotting, each of those basis segments will be shifted to the position where the basis segment obtains a cross-correlation peak and is within the tolerance zone of the congruent registration position. 

  
\begin{figure}[hbt]
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:sigplot}The dark grey line shows the comparison signature; each red line segment shows one congruent matching profile segment.}
```{r sigplot, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
sig.plot <- cmps_signature_plot(
  cmps_with_multi_scale
)
sig.plot$segment_shift_plot
```
\end{subfigure}
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:sigplot2}The dark grey line shows the comparison signature; the red line shows the reference signature. Solid part is the congruent matching profile segments, and the dashed part shows segments that do not agree with the congruent registration position.}
```{r sigplot2, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
sig.plot$signature_shift_plot
```
\end{subfigure}
\caption{\label{sigplots}\hh{The resulting two figures signature plots. We need a summarizing sentence here.}}
\end{figure}



The second element is called `signature_shift_plot`. \hh{It is shown in \autoref{fig:sigplot2}.} On this visual both the reference signature and the comparison signature are plotted. The reference signature is aligned with the comparison signature based on the congruent registration position. And the congruent matching profile segments are highlighted. 


Other elements of this list are `seg_shift`, `sig_shift`, and `seg.pos`. These elements are essentially used for generating visuals above but also provide insights about the best fitted position for each congruent matching profile segments and for the reference signature. `sig.plot$seg.pos` can also tell us which basis segments are the congruent matching profile segments. 

As `cmps_signature_plot` focuses on the signature level, on the other hand, `cmps_segment_plot` focuses on the segment level. It not only takes the "full result" of `extract_feature_cmps`, but also takes an argument `seg.idx`, which indicates which segment to be inspected. For example, after checking `sig.plot$seg_shift` we noticed that segment 6 is not one of the congruent matching profile segments. So we can set `seg.idx = 6` in order to have a closer look at segment 6 and why it disagrees with the congruent registration position. `cmps_segment_plot` also returns a list, of which each element corresponds to one segment scale of this basis segment. Then for each segment scale, we will have two plots, `segment_plot` and `scale_ccf_plot`.

Take the first element of `seg.plot` as an example, it corresponds to the first segment scale (the original scale) of the 6th basis segment and carries two plots, `segment_plot` and `scale_ccf_plot`.

Remember that when computing the CMPS score, we were using `npeaks.set = c(5, 3, 1)`. This means that for the first segment scale, 5 peaks are identified in the cross-correlation curve. `segment_plot` plots the 6th basis segment in its first scale at its original position as well as the positions where the basis segment obtains its 5 cross-correlation peaks. 



And the `scale_ccf_plot` plots the cross-correlation curve. We can see that 5 highest peaks are identified and marked on the plot. 


\begin{figure}
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:segplot}segment\_plot for segment 6 at scale 1. The original position of segment 6 is indicated by the solid black line. Positions where the segment achieves the 5 highest cross-correlations are indicated by the dashed line segments.}
```{r segplot, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
seg.plot <- cmps_segment_plot(
  cmps_with_multi_scale, 
  seg.idx = 6
)
seg.plot[[1]]$segment_plot
```
\end{subfigure}
\begin{subfigure}[t]{\textwidth}
\caption{\label{fig:segplot2}scale\_ccf\_plot shows the cross-correlation curve between the comparison signature and segment 6 at scale 1. The five highest peaks are marked by dots. The vertical red dashed line indicates the congruent registration position; the green dashed line shows a candidate position for the consistent correlation peak; the blue dashed lines show the region of the tolerance zone. We can see here none of the five highest peaks agrees with the candidate position, so a consistent correlation peak cannot be identified and we don't take segment 6 as a congruent matching profile segment}
```{r segplot2, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
seg.plot[[1]]$scale_ccf_plot
```
\end{subfigure}
\caption{\label{fig:segplots}some text.}
\end{figure}

<!-- ```{r, echo=FALSE, eval=FALSE, out.width="300px", fig.cap="segment\\_plot for segment 6 at scale 1. The original position of segment 6 is indicated by the solid black line. Positions where the segment achieves the 5 highest cross-correlations are indicated by the dashed line segments. "} -->
<!-- knitr::include_graphics("img/segplot1.png", dpi = 100) -->
<!-- ``` -->


<!-- ```{r, echo=FALSE, out.width="300px", fig.cap="scale\\_ccf\\_plot shows the cross-correlation curve between the comparison signature and segment 6 at scale 1. The five highest peaks are marked by dots. The vertical red dashed line indicates the congruent registration position; the green dashed line shows a candidate position for the consistent correlation peak; the blue dashed lines show the region of the tolerance zone. We can see here none of the five highest peaks agrees with the candidate position, so a consistent correlation peak cannot be identified and we don't take segment 6 as a congruent matching profile segment"} -->
<!-- knitr::include_graphics("img/segplot2.png", dpi = 100) -->
<!-- ``` -->

Additionally, if we put `segment_plot` and `scale_ccf_plot` for all three segment scales together, we can have more insights about why segment 6 is not a congruent matching profile segment. 

\begin{figure}
```{r segplot3, opts.label="codefig", echo=TRUE, out.width='\\textwidth', warning = FALSE}
library(ggpubr)

ggarrange(
  plotlist = 
    unlist(seg.plot, 
           recursive = FALSE),
  ncol = 2, 
  nrow = 3)
```
\caption{\label{fig:seg_all} Put segment\_plot and scale\_ccf\_plot of all scales together. We are identifying five highest peaks at scale 1, three peaks at scale 2, and one peak at scale 3 since npeaks.set = c(5, 3, 1). Putting these plots together can help better understand why segment 6 is not a congruent matching profile segment. Here we can also see clearly that increasing segment length can reduce the number of false positive peaks.}
\end{figure}

<!-- ```{r, echo=FALSE, out.width="400px", fig.cap="put segment\\_plot and scale\\_ccf\\_plot of all scales together. We are identifying five highest peaks at scale 1, three peaks at scale 2, and one peak at scale 3 since npeaks.set = c(5, 3, 1). Putting these plots together can help better understand why segment 6 is not a congruent matching profile segment. Here we can also see clearly that increasing segment length can reduce the number of false positive peaks."} -->
<!-- knitr::include_graphics("img/segplot3.png", dpi = 100) -->
<!-- ``` -->

The red vertical dashed line indicates the congruent registration position. We can see that the segment 6 does obtain a peak near to the congruent registration position at scale two and scale three, respectively; however, this position doesn't give one of the five highest peaks at scale one. As a result, segment 6 fails to identify the consistent correlation peak (ccp) and fails to become one of the congruent matching profile segments according to the multi segment lengths strategy. 

## Results

**Metrics Based on CMPS scores**

```{r, eval=FALSE, echo=FALSE}
hamby252_results <- readRDS("C:/Research/Bullet/Bullet_Rcode/hamby252_results.rds")
hamby44_results <- readRDS("C:/Research/Bullet/Bullet_Rcode/hamby44_results.rds")
```


As presented in the work of @cmps, researchers applied the CMPS method to one of the Hamby set scans (Hamby 252). In order to show that our implementation of the CMPS algorithm is able to reproduce the results in (original paper) and is able to be used for other data sets, we applied our implementation to both Hamby set 252 and Hamby set 44. Since the CMPS algorithm works with, in our case, bullet signatures, we conducted some data-processing. For both Hamby 252 and Hamby 44, we started with x3p files in the database, followed the framework proposed by Hare and Hofmann using the same set of parameters for both data sets, removed outliers, and obtained bullet signatures for each bullet land engraving. Note that in the work of @cmps they used a different framework to obtain bullet signatures. However, since NIST's work is not open-source, we were not able to follow their framework and were only able to reproduce the results for Hamby set 252 qualitatively.

The CMPS score can be considered as a similarity score of two signatures. Then how can we get a similarity score of two bullets based on CMPS scores? In (the original paper) researchers introduced two similarity metrics, $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$, for bullet comparisons based on CMPS scores of bullet signature comparisons. For example, there are in total 6 $\times$ 6 signature comparisons in order to compare two bullets in Hamby study since each bullet has 6 LEAs and each LEA generates a bullet signature. And a CMPS score will be found for every signature comparison. $\mathrm{CMPS_{max}}$ is the highest CMPS score among all signature comparisons. And $\mathrm{\overline{CMPS}_{max}}$ is the highest possible average CMPS score of signature comparisons that are in the same phase.

Here are the CMPS scores of all 36 signature comparisons of the bullets in the example above.

```{r}
#      [,1] [,2] [,3] [,4] [,5] [,6]
# [1,]    2    3    2    3    1    2
# [2,]    2    1   17    1    2    3
# [3,]    1    1    3   14    2    2
# [4,]    2    1    1    1   10    1
# [5,]    2    2    1    1    1   15
# [6,]   16    3    1    2    1    1
```

In this example, the $\mathrm{CMPS_{max}}=17$ and $\mathrm{\overline{CMPS}_{max}}=(16+3+17+14+10+15)/6=12.5$. 

**Hamby 252**

Figure 2 shows the distribution of $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$ after we applied the CMPS algorithm to Hamby set 252. Although the CMPS scores we found here are not exactly the same as those presented in the [original paper] since we don't have the exact parameters and functions used by the researchers, the results we obtained are promising. For both $\mathrm{CMPS_{max}}$ and $\mathrm{\overline{CMPS}_{max}}$ we can observe a clear separation between the known matching comparisons (KM) and known non-matching comparisons (KNM). Table x shows some summary statistics. 

The parameters we used in `extract_feature_cmps` are:

```{r, eval=FALSE}
extract_feature_cmps(
  x, y,
  seg_length = 50,
  Tx = 25,
  npeaks.set = c(5,3,1),
  include = "nseg"
)
```

Note that for Hamby set 44, one unit represents 1.5625 \textmu m so setting `seg_length = 50` makes each basis segment have length 78.125 \textmu m. And `Tx = 25` makes the tolerance zone be $\pm 39.0625$ \textmu m. This is to mimic the parameters used in the [original paper].

<!-- this is figure 2 -->
```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 252; removed outliers; seg\\_length = 50, Tx = 25, npeaks.set = c(5,3,1) "}
# [4] "span1=0.25, span2=0.03, rm_outliers = TRUE, 5025, 531"  
knitr::include_graphics("img/hamby252_v1.png", dpi = 100)
```

table 1:

```{r, echo=FALSE}
library(knitr)
library(kableExtra)
# rtt <- readRDS("summary_table.rds")
# colnames(rtt) <- 
rtt <- data.frame(parameters = c("span1=0.25, (5, 3, 1)", "span1=0.25, (10, 6, 1)", "span1=0.75, (5, 3, 1)"),
                  p1 = c(7,9,6),
                  p2 = c(10, 13, 11),
                  p3 = c(3.6, 4.833, 3.167),
                  p4 = c(6.667, 9.167, 6.6))
colnames(rtt) <- c("Parameters",
                   "$\\mathrm{CMPS_{max}}$ KNM's max",
                   "$\\mathrm{CMPS_{max}}$ KM's min",
                   "$\\mathrm{\\overline{CMPS}_{max}}$ KNM's max",
                   "$\\mathrm{\\overline{CMPS}_{max}}$ KM's min")

knitr::kable(rtt, "latex", booktabs = TRUE, escape = FALSE,
             caption = "min and max of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ showing the separation between KNM and KM",
             row.names = FALSE, digits = 4) %>% 
  column_spec(2:5, width = "2cm")
```



Figure 3 shows the results for Hamby set 44. Again, we are able to see a clear separation between the KM comparisons and the KNM comparisons, but it would be better if the separation can be further enlarged. Table 1 shows some summary statistics for Hamby set 44. 

For Hamby set 44, the parameters we used in `extract_feature_cmps` are:

```{r, eval=FALSE}
extract_feature_cmps(
  x, y,
  seg_length = 61, 
  Tx = 30,
  npeaks.set = c(5,3,1),
  include = "nseg"
)
```

Note that we used different values here for `seg_length` and `Tx` because our Hamby set 44 scans have a different scanning resolution. One unit here represents 1.29 \textmu m. So here each basis segment has length 78.69 \textmu m, and the tolerance zone is $\pm 38.7$ \textmu m.

<!-- this is figure 3 -->

```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 44; removed outliers; seg\\_length = 61, Tx = 30, npeaks.set = c(5,3,1), span1=0.25"}
# [1] "span1=0.25, span2=0.03, rm_outliers"
knitr::include_graphics("img/hamby44_v1.png", dpi = 100)
```

Figure 4 shows another Hamby set 44 results, but the parameter `npeaks.set` is now `c(10, 6, 1)`. We can see that the separation between KM comparisons and KNM comparisons is increased. This shows that the parameters used in the CMPS algorithm can affect the CMPS results, and an open-source implementation of the algorithm will facilitate efforts of cross-validating these parameters.

<!-- this is figure 4 -->

```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 44; removed outliers; seg\\_length = 61, Tx = 30, npeaks.set = c(10,6,1), span1=0.25 "}
# [5] "span1=0.25, span2=0.03, rm_outliers, c(10,6,1)"
knitr::include_graphics("img/hamby44_c1_v1.png", dpi = 100)
```

For the results above we used `span1=0.25` in the function `cc_get_signature` when computing the signatures; however, in this example we used `span1=0.75` and changed the characteristic of those signatures. As we can see in figure 5, this change also affects the CMPS results.

<!-- this is figure 5 -->

```{r, echo=FALSE, out.width="400px", fig.cap="Distribution of $\\mathrm{CMPS_{max}}$ and $\\mathrm{\\overline{CMPS}_{max}}$ for Hamby 44; removed outliers; seg\\_length = 61, Tx = 30, npeaks.set = c(5,3,1), span1=0.75"}
# [4] "span1=0.75, span2=0.03, rm_outliers"  
knitr::include_graphics("img/hamby44_c2_v1.png", dpi = 100)
```

[The codes generating those results can be found in the appendix. ???]


## Conclusion

We presented the CMPS package, an open-source implementation of the congruent matching profile segments (CMPS) algorithm. The CMPS algorithm was proposed by NIST in 2019 and was made for objective tool marks comparisons. In this paper, functions included in the package were illustrated along with the basic logic of the CMPS algorithm. 
And we used a small dataset included in the package as an example to explain the usage of the package. Some graphing tools were also implemented in the package so that users can visualize results and have a better understanding of both the algorithm and the results. We also applied the algorithm to two datasets in Hamby study (Hamby set 252 and Hamby set 44), and the results we obtained were promising. 

From the results of both Hamby set 252 and 44, we can see that the CMPS scores of KM comparisons computed by `extract_feature_cmps` were able to be separated from those of KNM comparisons. And at the same time, we can see that CMPS algorithm is sensitive to the choice of parameters such as segment length, number of peaks detected at each segment scale, and congruency tolerance. Some parameter choices are better in the sense that they can enlarge the separation between the KM comparisons and the KNM comparisons. And the best set of parameters depend on the dataset being used, and the choice of parameters has not been, but should be, cross-validated. 

Our open-source implementation introduces the CMPS algorithm to R community and allows everyone to use it for their own projects. It would also facilitate future studies on parameter cross-validation and the development of statistical methods to modeling KM and KNM CMPS score distributions.  

<!-- open source -->
<!-- module -->
<!-- hamby 44 new data set -->
<!-- hamby 252 -->
<!-- threshold -->


### About this format and the R Journal requirements

`rticles::rjournal_article` will help you build the correct files requirements: 

* A R file will be generated automatically using `knitr::purl` - see
https://bookdown.org/yihui/rmarkdown-cookbook/purl.html for more information.
* A tex file will be generated from this Rmd file and correctly included in
`RJwapper.tex` as expected to build `RJwrapper.pdf`.
* All figure files will be kept in the default rmarkdown `*_files` folder. This
happens because `keep_tex = TRUE` by default in `rticles::rjournal_article`
* Only the bib filename is to modifed. An example bib file is included in the
template (`RJreferences.bib`) and you will have to name your bib file as the
tex, R, and pdf files.
